[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT112 Notebook",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation."
  },
  {
    "objectID": "bw/bw-uni.html",
    "href": "bw/bw-uni.html",
    "title": "\n1  Univariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking univariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\n### UNIVARIATE VIZUALIZATION ###\n\n# Import Data \nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\n\n# Download Tidyverse\nlibrary(tidyverse)\n\n# Create Univariate Visualization with improvements\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"steelblue\", fill = \"skyblue\", width = 0.8) +   # Adjust colors and width\n  labs(\n    title = \"Distribution of Hike Ratings\",                        # Add title\n    x = \"Hike Rating\",                                             # Label x-axis\n    y = \"Frequency of Hikes\") +                                    # Label y-axis\n  theme_minimal() +                                                # Clean background\n  theme(plot.title = element_text(face = \"bold\"))                  # Make the title bold"
  },
  {
    "objectID": "bw/bw-bi.html",
    "href": "bw/bw-bi.html",
    "title": "\n2  Bivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking bivariate visualization. The visualization will not perfect the first time but you are expected to improve it throughout the semester especially after covering advanced topics such as effective viz.\n\n### BIVARIATE VIZUALIZATION ###\n\n#Load GGPLOT \nlibrary(ggplot2)\n\n# Load Data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n#Create Plot\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.55) +                                 # Add transparency\n  scale_fill_manual(values = c(\"blue\",\"purple\",\"red\"),         # Add partisan colors                \n            name = \"Historical Voting Pattern\",                # Added title to the legend\n            labels = c(\"Democrat\", \"Swing\", \"Republican\")) +   # Add labels \n  labs(\n    title = \"Density Plot of Republican Vote Share in 2020 by Historical Vote\",\n    x = \"Republican Vote Percentage (2020)\",\n    y = \"Density\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"), # Center and bold the title\n    legend.position = \"bottom\")                            # Place legend at the bottom"
  },
  {
    "objectID": "bw/bw-tri.html",
    "href": "bw/bw-tri.html",
    "title": "\n3  Trivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking trivariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\n# Import Education Data\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nhead(education)\n\n       State expend ratio salary frac verbal math  sat  fracCat\n1    Alabama  4.405  17.2 31.144    8    491  538 1029   (0,15]\n2     Alaska  8.963  17.6 47.951   47    445  489  934 (45,100]\n3    Arizona  4.778  19.3 32.175   27    448  496  944  (15,45]\n4   Arkansas  4.459  17.1 28.934    6    482  523 1005   (0,15]\n5 California  4.992  24.0 41.078   45    417  485  902  (15,45]\n6   Colorado  5.443  18.4 34.571   29    462  518  980  (15,45]\n\n\n\n# Download Library \nlibrary(ggplot2)\n\n# Create Density Plot\nggplot(education, aes(x = sat, fill = fracCat)) + \n  geom_density(alpha = 0.6) + #Adjust Transparency \n  labs(\n    title = \"SAT Score Distributions by Student Participation Rate\",\n    x = \"SAT Total Score\",\n    y = \"Density\",\n    fill = \"SAT Participation Rate (%)\") +\n  theme_minimal() + # Cleaner theme\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15, hjust = 0.5), # Make Title Bold and Centered\n    legend.position = \"right\") #Position the Legend on the right \n\n\n\n\n\n4 Reflection\nThis visualization demonstrates the relationship between three variables related to education and SAT scores across different states.\n\nThe x-axis represents student’s combined score of the verbal and math sections of the SAT. Higher values indicate better overall performance on the SAT.\nThe y-axis shows shows the probability density of the SAT scores within each category of fracCat. In other words, the height of the curves at any given SAT score shows how concentrated the scores are for states within that fracCat group.\nThe Color/Fill displays the fracCat (Proportion of Students Taking the SAT). This is the third variable, categorized into three groups: States where a very small proportion (0 to 15%) took the SAT; States where a moderate proportion (between 15% and 45%) took the SAT; and States where a high proportion (greater than 45% up to 100%) took the SAT.\n\nThe most striking takeaway is the clear inverse relationship between the fraction of students taking the SAT and the overall distribution of SAT scores in a state. In states with low participation, the average scores tend to be inflated. Conversely, in states with much higher participation, the average scores tend to be lower.\n\n# Create A Scatter Plot with Linear Regression Lines\nlibrary(ggplot2)\nggplot(education, aes(x = expend, y = sat, color = fracCat)) +\n  geom_point(alpha = 0.7, size = 3) +  #Adjust Transparency and Point Size\n  geom_smooth(method = \"lm\", se = TRUE, linewidth = 1) + # Keep regression lines with confidence intervals\n  labs(\n    title = \"Expenditure Per Student and SAT Scores by Participation Rate\",\n    x = \"Expenditure per Student\",\n    y = \"SAT Total Score\",\n    color = \"SAT Participation Rate\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15, hjust = 0.5), # Make Title Bold and Centered\n    legend.position = \"bottom\") # Move the legend to the bottom\n\n\n\n\n\n5 Reflection\nThis Scatter Plot displays the relationship between two numerical variables, Expenditure Per Student (on the x-axis) and SAT Total Score (on the y-axis). The third variable, SAT Participation Rate, is introduced through the color of the data points and the separate linear regression lines.This trivariate visualization demonstrates that the proportion of students taking the SAT seems to be a stronger predictor of average SAT scores than expenditure per student. States with lower SAT participation rates tend to have higher average scores, regardless of their spending per student. Conversely, states with high participation rates tend to have lower average scores."
  },
  {
    "objectID": "bw/bw-quad.html",
    "href": "bw/bw-quad.html",
    "title": "\n4  Quadvariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking quadvariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\n# Load Necessary Libraries\nlibrary(tidyverse)\nlibrary(fivethirtyeight)\nlibrary(ggplot2)\n\n# Create `new_bechdel` Dataset\nnew_bechdel &lt;- bechdel |&gt;\n  mutate(clean_test = factor(clean_test, c(\"nowomen\", \"notalk\", \"men\", \"dubious\", \"ok\"))) |&gt;\n  mutate(half_decades = cut(year, breaks = seq(1969, 2014, by = 5)))\n\n\n# Create Quadvariate Vizualization \n\nggplot(new_bechdel, aes(x = budget, y = domgross, color = binary)) +\n  geom_point(alpha = 0.7, size = 0.5) +\n  geom_smooth(method = \"lm\") + \n  facet_wrap(~ clean_test,  labeller = labeller(clean_test = c(\"nowomen\" = \"No Women\",\n                                                \"notalk\" = \"No Talk\",\n                                                \"men\" = \"Men Only\",\n                                                \"dubious\" = \"Dubious\",\n                                                \"ok\" = \"Passes\")),\n             ncol = 3, # Specify the number of columns for the facets\n             scales = \"free_x\") + # Allow x-axis scales to vary if needed +\n  labs(\n    title = \"Bechdel Test Results by Reason for Failure\",\n    x = \"Budget (in USD)\",\n    y = \"Domestic Gross (in USD)\",\n    color = \"Bechdel Test Result\") +\n  theme_minimal() + \n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 16),\n    axis.title.x = element_text(face = \"bold\", size = 12),\n    axis.title.y = element_text(face = \"bold\", size = 12),\n    legend.title = element_text(face = \"bold\", size = 12),\n    strip.text = element_text(face = \"bold\", size = 11),\n    panel.spacing.x = unit(1, \"cm\"), # Adjust horizontal spacing between facets\n    panel.spacing.y = unit(1, \"cm\"), # Adjust vertical spacing between facets\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10), # Angle x-axis text\n    axis.text.y = element_text(size = 10),\n    plot.margin = margin(1, 1, 1, 1, \"cm\") # Add overall plot margins\n  )"
  },
  {
    "objectID": "bw/bw-spatial.html",
    "href": "bw/bw-spatial.html",
    "title": "\n5  Spatial Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking spatial visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\n5.0.1 Spacial Vizualization: Exercise #10\nConstruct county-level maps of median_rent and median_age.\n\n#Load Libraries \n# Load necessary libraries\nlibrary(leaflet)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n# Download Datasets\nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n# Wrangle the Data\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\n\n# Get Latitude and Longitude Coordinates of States\nstates_map &lt;- map_data(\"state\")\n\n# Check It Out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\n\n# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\n\n# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\n\n# Create A County-Level Map of median_rent \nlibrary(ggplot2)\nlibrary(viridis) # For better color palettes\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n    geom_map(map = county_map) +\n    expand_limits(x = county_map$long, y = county_map$lat) +\n    coord_equal() +\n    scale_fill_viridis_c(name = \"Median Monthly Rent ($)\", option = \"magma\") + # Using a viridis palette\n    theme_void() + # Cleaner background\n    theme(legend.position = \"right\",\n          plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"), # Centered, larger title\n          plot.subtitle = element_text(hjust = 0.5, size = 12), # Centered subtitle\n          plot.caption = element_text(hjust = 0, size = 10, color = \"black\")) + # Left-aligned caption\n    labs(title = \"Median Rent by County in the United States\",\n         subtitle = \"Estimated for 2020\")\n\n\n\n\nThe “Median Rent by County in the United States’ visualization helps us understand the spatial patterns of median monthly rent across the United States at the county level in 2020. It highlights regional disparities and the influence of living in a coastal and/or metropolitan areas on housing costs. The lightest areas on the map, representing the highest median monthly rents, are predominantly concentrated along the coasts. Additionally, major inland metropolitan areas, such as Chicago, Denver, and Dallas, also exhibit higher median rents compared to their surrounding areas.\nNote On Missing Data: It’s important to note that there are some counties that appear black on the map, indicating missing data for the median rent in those specific counties for the year 2020."
  },
  {
    "objectID": "bw/Exam-one.html",
    "href": "bw/Exam-one.html",
    "title": "\n6  Exam 1\n",
    "section": "",
    "text": "#Download Food Consumption and CO2 Emissions Dataset\nfood_consumption &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-18/food_consumption.csv')\n\nfood_consumption\n\n# A tibble: 1,430 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 1,420 more rows\n\n\nUsing an appropriate viz, you need to answer the following grand research question: What does the consumption of each food category in each country look like?\n\n# Install Packages \nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\n\n# Get Data\ntuesdata &lt;- tt_load('2020-02-18')\nfc &lt;- tuesdata$food_consumption \n\n\n# Understand Data - List some initial steps that should be carried after loading the above dataset\nhead(fc)\n\n# A tibble: 6 × 4\n  country   food_category consumption co2_emmission\n  &lt;chr&gt;     &lt;chr&gt;               &lt;dbl&gt;         &lt;dbl&gt;\n1 Argentina Pork                10.5          37.2 \n2 Argentina Poultry             38.7          41.5 \n3 Argentina Beef                55.5        1712   \n4 Argentina Lamb & Goat          1.56         54.6 \n5 Argentina Fish                 4.36          6.96\n6 Argentina Eggs                11.4          10.5 \n\nnrow(fc)\n\n[1] 1430\n\ndim(fc)\n\n[1] 1430    4\n\nstr(fc)\n\nspc_tbl_ [1,430 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ country      : chr [1:1430] \"Argentina\" \"Argentina\" \"Argentina\" \"Argentina\" ...\n $ food_category: chr [1:1430] \"Pork\" \"Poultry\" \"Beef\" \"Lamb & Goat\" ...\n $ consumption  : num [1:1430] 10.51 38.66 55.48 1.56 4.36 ...\n $ co2_emmission: num [1:1430] 37.2 41.53 1712 54.63 6.96 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   country = col_character(),\n  ..   food_category = col_character(),\n  ..   consumption = col_double(),\n  ..   co2_emmission = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nWhat are the units of observations?\nUnits: Country, Food, Category\nThere are 11 Food Categories.\nThere are 130 Countries.\n\n# Grouped By Bar Plot (Faceted by Food Category)\n\nggplot(food_consumption, aes(x = country, y = consumption)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") + \n  facet_wrap(~ food_category, scales = \"free_y\") +\n  labs(\n    title = \"Consumption of Food Categories Across Countries\",\n    x = \"Country\",\n    y = \"Consumption\"\n  ) +\n  theme_bw() +  \n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank()) \n\n\n\n\nI decided to try doing a Bar Chart Faceted by Food Category. Essentially, for each food category (faceted), you have a 11 bar charts (one per food category) where the y-axis represents countries and the x-axis represents consumption. Within each chart, you have bars for each 130 countries. This type of visualization is good for sing the diversity of consumption levels across the world. However, with 130 countries (130 bars) it makes it difficult to interpret each of the individual values and identify any particular country. If the visualization was interactive, where one could zoom in and out - that may improve it and make it more legible. While not the perfect Viz, I do think this is very useful way to display the data. In Exam #2, we take this research question further and use spatial data to create 11 maps showing the levels of consumption across the world for each of the 11 food categories."
  },
  {
    "objectID": "bw/Exam-two.html",
    "href": "bw/Exam-two.html",
    "title": "\n7  Exam 2\n",
    "section": "",
    "text": "#Download Food Consumption and CO2 Emissions Dataset\nfood_consumption &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-18/food_consumption.csv')\n\n# Install via pak::pak(\"dslc-io/tidytuesdayR\")\n\ntuesdata &lt;- tidytuesdayR::tt_load('2020-02-18')\ntuesdata &lt;- tidytuesdayR::tt_load(2020, week = 8)\n\n\nfood_consumption &lt;- tuesdata$food_consumption\n\n\n# 2.1 Data Dictionary (View Data)\nfood_consumption\n\n# A tibble: 1,430 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 1,420 more rows\n\n\n\n# 2.2 Load Packages/Libraries\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(rnaturalearth)  # for country boundaries \nlibrary(sf)             # for spatial viz \nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n# 2.3 Load Data \ntuesdata &lt;- tt_load('2020-02-18')\nfc &lt;- tuesdata$food_consumption\n\n\n# 2.4 Inspect Data \nstr(fc)\n\nspc_tbl_ [1,430 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ country      : chr [1:1430] \"Argentina\" \"Argentina\" \"Argentina\" \"Argentina\" ...\n $ food_category: chr [1:1430] \"Pork\" \"Poultry\" \"Beef\" \"Lamb & Goat\" ...\n $ consumption  : num [1:1430] 10.51 38.66 55.48 1.56 4.36 ...\n $ co2_emmission: num [1:1430] 37.2 41.53 1712 54.63 6.96 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   country = col_character(),\n  ..   food_category = col_character(),\n  ..   consumption = col_double(),\n  ..   co2_emmission = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead (fc, 22)\n\n# A tibble: 22 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 12 more rows\n\n\n\n# 2.7 Fix food_category Variable \nfcc &lt;- food_consumption |&gt; \n  mutate(food_category = fct_recode(food_category,\n  \"Lamb\" = \"Lamb & Goat\",\n  \"Dairy\" = \"Milk - inc. cheese\",\n  \"Wheat\" = \"Wheat and Wheat Products\",\n  \"Nuts\" = \"Nuts inc. Peanut Butter\"))\n\nfcc$food_category #2.8 make sure the new values of food_category variable are as expected \n\n   [1] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n   [9] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n  [17] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n  [25] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n  [33] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n  [41] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n  [49] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n  [57] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n  [65] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n  [73] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n  [81] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n  [89] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n  [97] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [105] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [113] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [121] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [129] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [137] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [145] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [153] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [161] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [169] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [177] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [185] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [193] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [201] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [209] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [217] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [225] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [233] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [241] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [249] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [257] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [265] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [273] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [281] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [289] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [297] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [305] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [313] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [321] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [329] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [337] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [345] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [353] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [361] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [369] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [377] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [385] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [393] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [401] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [409] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [417] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [425] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [433] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [441] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [449] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [457] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [465] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [473] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [481] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [489] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [497] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [505] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [513] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [521] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [529] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [537] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [545] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [553] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [561] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [569] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [577] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [585] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [593] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [601] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [609] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [617] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [625] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [633] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [641] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [649] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [657] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [665] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [673] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [681] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [689] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [697] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [705] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [713] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [721] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [729] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [737] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [745] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [753] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [761] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [769] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [777] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [785] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [793] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [801] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [809] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [817] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [825] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [833] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [841] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [849] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [857] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [865] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [873] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [881] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [889] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [897] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [905] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [913] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [921] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [929] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [937] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [945] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [953] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [961] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [969] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [977] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [985] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [993] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1001] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1009] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1017] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1025] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1033] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1041] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1049] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1057] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1065] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1073] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n[1081] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1089] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1097] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1105] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1113] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1121] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1129] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1137] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1145] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1153] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1161] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n[1169] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1177] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1185] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1193] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1201] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1209] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1217] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1225] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1233] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1241] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1249] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n[1257] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1265] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1273] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1281] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1289] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1297] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1305] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1313] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1321] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1329] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1337] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n[1345] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1353] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1361] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1369] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1377] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1385] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1393] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1401] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1409] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1417] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1425] Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \nLevels: Beef Eggs Fish Lamb Dairy Nuts Pork Poultry Rice Soybeans Wheat\n\n\n\n# 3 - Which 5 countries consume the most food?\ntop_five_countries &lt;- fcc |&gt;\n  group_by(country) |&gt;\n  summarize(consumption = sum(consumption)) |&gt;\n  arrange(desc(consumption)) |&gt;\n  head(5)\n\ntop_five_countries\n\n# A tibble: 5 × 2\n  country     consumption\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Finland            640.\n2 Lithuania          555.\n3 Sweden             550 \n4 Netherlands        534.\n5 Albania            533.\n\n\n\n# Make The Plot \nggplot(top_five_countries, aes(x = reorder(country, consumption), y = consumption)) +\n  geom_col(fill = \"steelblue\") +\n  labs(\n    title = \"Top 5 Countries by Total Food Consumption\",\n    x = \"Country\",\n    y = \"Consumption\") +\n  theme_minimal()\n\n\n\n\n\n# 4 - Which Top 5 Countries Consume Each Food?\n\n#Find The Top Five Countries By Consumption For Each Food Category \ntop_five_per_food &lt;- fcc |&gt;\n  group_by(food_category, country) |&gt;\n  summarize(consumption = sum(consumption), .groups = \"drop\") |&gt;\n  arrange(food_category, desc(consumption)) |&gt;\n  group_by(food_category) |&gt;\n  slice_head(n = 5)\n\n\n#Plot The Visualization Using geom_col and facet_wrap\nggplot(top_five_per_food, aes(x = reorder(country, consumption), y = consumption)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = round(consumption, 1)), hjust = -0.1, size = 3) +  # Adjusted hjust for spacing\n  facet_wrap(~ food_category, scales = \"free_y\", ncol = 2) +  # Changed scales to \"free_y\"\n  coord_flip() +\n  labs(\n    title = \"Top 5 Countries by Consumption for Each Food Category\",\n    x = \"Country\",\n    y = \"Consumption (kg/person/year)\" ) +\n  theme_minimal() \n\n\n\n\n\n# 5 - What does the consumption of each food look like? \n\n#Attempt 3\nne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = ifelse(name == \"United States of America\", \"USA\", name)) |&gt;\n  mutate(name = ifelse(name == \"Bosnia and Herz.\", \"Bosnia and Herzegovina\", name)) |&gt;\n  mutate(name = ifelse(name == \"Czechia\", \"Czech Republic\", name)) |&gt;\n  mutate(name = ifelse(name == \"Taiwan\", \"Taiwan. ROC\", name)) |&gt;\n  left_join(\n    fcc |&gt;\n      select(-co2_emmission) |&gt;\n      group_by(food_category) |&gt;\n      mutate(consumption = (consumption - mean(consumption))/sd(consumption)), join_by(name == country)) |&gt;\n  pivot_wider(names_from = food_category, values_from = consumption) |&gt;\n  select(-\"NA\") |&gt;\n  pivot_longer(cols = c(-name, -geometry), \n               names_to = \"food_category\", \n               values_to = \"consumption\") |&gt;\n  ggplot() + \n  geom_sf(aes(fill = consumption)) + \n  facet_wrap(~food_category, ncol = 4) + \n  scale_fill_viridis_c(option = \"plasma\", na.value = \"white\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 14),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(size = 10))"
  },
  {
    "objectID": "bw/SoloProject.html",
    "href": "bw/SoloProject.html",
    "title": "\n8  Solo Project\n",
    "section": "",
    "text": "For my solo project, I wanted to visualize the shifts in Democratic voteshare across Minnesota’s eight congressional districts between the 2022 midterm elections and the 2024 general election. This project involved collecting certified election results from both cycles, calculating the change in Democratic voteshare, and displaying those shifts through a comparative visual format.\n\n# Load Necessary Libraries\nlibrary(tigris)\nlibrary(leaflet)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(stringr)\n\n# Load United States Congressional Districts\ncd118 &lt;- congressional_districts(cb = TRUE, resolution = \"20m\", year = 2022)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |======================================================================| 100%\n\n# Create Map\nleaflet(cd118) |&gt;\n  addTiles() |&gt;\n  addPolygons()\n\n\n\n\n\n\n# Define Minnesota Congressional Districts\nmn_cd &lt;- congressional_districts(state = \"MN\", cb = TRUE, resolution = \"20m\", year = 2022)\n\n# Create Map\nleaflet(mn_cd) |&gt;\n  addTiles() |&gt;\n  addPolygons(\n    label = ~paste(\"District\", CD118FP),)\n\n\n\n\n\n\n#Import 2022 Minnesota Congressional Results \ndata_2022 &lt;- read_delim(\"../data/Election_Results_2022\", col_names = FALSE)\n\n# Clean and filter data\nMinnesota_Congressional_Results_2022 &lt;- data_2022 |&gt;\n  select(X6, X11, X15) |&gt;\n  rename(District = X6,\n         Party = X11,\n         Voteshare = X15) |&gt;\n  filter(Party %in% c(\"DFL\", \"R\"))  # Filter for DFL and R parties\n\nMinnesota_Congressional_Results_2022\n\n# A tibble: 16 × 3\n   District Party Voteshare\n      &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        1 R          53.8\n 2        1 DFL        42.3\n 3        2 R          45.6\n 4        2 DFL        50.9\n 5        3 R          40.4\n 6        3 DFL        59.6\n 7        4 R          32.3\n 8        4 DFL        67.6\n 9        5 R          24.5\n10        5 DFL        74.3\n11        6 R          62.0\n12        6 DFL        37.8\n13        7 R          67.0\n14        7 DFL        27.6\n15        8 R          57.2\n16        8 DFL        42.7\n\n\n\n#Import 2024 Minnesota Congressional Results \ndata_2024 &lt;- read_delim(\"../data/Election_Results_2024\", col_names = FALSE)\n\nMinnesota_Congressional_Results_2024 &lt;- data_2024 |&gt;\n  select(X6, X11, X15) |&gt;\n  rename(District = X6,\n         Party = X11,\n         Voteshare = X15)  |&gt;\n  filter(Party %in% c(\"DFL\", \"R\"))  # Keep only DFL and R parties \n\nMinnesota_Congressional_Results_2024\n\n# A tibble: 16 × 3\n   District Party Voteshare\n      &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        1 DFL        41.4\n 2        1 R          58.5\n 3        2 R          42.1\n 4        2 DFL        55.5\n 5        3 DFL        58.4\n 6        3 R          41.4\n 7        4 R          32.6\n 8        4 DFL        67.2\n 9        5 R          24.6\n10        5 DFL        74.4\n11        6 R          62.4\n12        6 DFL        37.4\n13        7 DFL        29.4\n14        7 R          70.4\n15        8 DFL        41.9\n16        8 R          58.0\n\n\n\n#Combine 2022 and 2024 Data\nMinnesota_Congressional_Results_2022 &lt;- Minnesota_Congressional_Results_2022 |&gt;\n  mutate(Year = 2022)\n\nMinnesota_Congressional_Results_2024 &lt;- Minnesota_Congressional_Results_2024 |&gt;\n  mutate(Year = 2024)\n\nCombined_Minnesota_Congressional_Results &lt;- bind_rows(\n  Minnesota_Congressional_Results_2022,\n  Minnesota_Congressional_Results_2024)\n\n# Fix District Variable (To Match Geographic Data)\nCombined_Minnesota_Congressional_Results$District &lt;- sprintf(\"%02d\", Combined_Minnesota_Congressional_Results$District)\n\nCombined_Minnesota_Congressional_Results\n\n# A tibble: 32 × 4\n   District Party Voteshare  Year\n   &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 01       R          53.8  2022\n 2 01       DFL        42.3  2022\n 3 02       R          45.6  2022\n 4 02       DFL        50.9  2022\n 5 03       R          40.4  2022\n 6 03       DFL        59.6  2022\n 7 04       R          32.3  2022\n 8 04       DFL        67.6  2022\n 9 05       R          24.5  2022\n10 05       DFL        74.3  2022\n# ℹ 22 more rows\n\n\n\n# Create the 'year_party' column for pivoting\nCombined_Minnesota_Congressional_Results &lt;- Combined_Minnesota_Congressional_Results |&gt;\n  mutate(year_party = paste0(tolower(Party), \"_\", Year))\n\n# Pivot The Data\nvoteshare_data &lt;- Combined_Minnesota_Congressional_Results |&gt;\n  pivot_wider(id_cols = District,\n              names_from = year_party,\n              values_from = `Voteshare`)\n\n# View Data \nvoteshare_data\n\n# A tibble: 8 × 5\n  District r_2022 dfl_2022 dfl_2024 r_2024\n  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 01         53.8     42.3     41.4   58.5\n2 02         45.6     50.9     55.5   42.1\n3 03         40.4     59.6     58.4   41.4\n4 04         32.3     67.6     67.2   32.6\n5 05         24.5     74.3     74.4   24.6\n6 06         62.0     37.8     37.4   62.4\n7 07         67.0     27.6     29.4   70.4\n8 08         57.2     42.7     41.9   58.0\n\n\n\nmn_cd_with_results &lt;- left_join(mn_cd, voteshare_data, by = c(\"CD118FP\" = \"District\"))\n\n# View Merged Data\nmn_cd_with_results\n\nSimple feature collection with 8 features and 13 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -97.22904 ymin: 43.49952 xmax: -89.48923 ymax: 49.38436\nGeodetic CRS:  NAD83\n  STATEFP CD118FP      AFFGEOID GEOID                 NAMELSAD LSAD CDSESSN\n1      27      05 5001800US2705  2705 Congressional District 5   C2     118\n2      27      03 5001800US2703  2703 Congressional District 3   C2     118\n3      27      06 5001800US2706  2706 Congressional District 6   C2     118\n4      27      02 5001800US2702  2702 Congressional District 2   C2     118\n5      27      08 5001800US2708  2708 Congressional District 8   C2     118\n6      27      04 5001800US2704  2704 Congressional District 4   C2     118\n7      27      01 5001800US2701  2701 Congressional District 1   C2     118\n8      27      07 5001800US2707  2707 Congressional District 7   C2     118\n        ALAND      AWATER r_2022 dfl_2022 dfl_2024 r_2024\n1   338801630    16523525  24.53    74.33    74.37  24.56\n2  1212366766   126629346  40.37    59.56    58.43  41.45\n3  6434599477   338776646  61.97    37.79    37.42  62.45\n4  4474617907   212911547  45.65    50.87    55.53  42.08\n5 80910616387 15048680132  57.18    42.72    41.92  57.99\n6   785198132    79844458  32.26    67.59    67.25  32.58\n7 31696870236   561074371  53.83    42.31    41.41  58.51\n8 80391767022  2552744290  66.95    27.61    29.44  70.45\n                        geometry\n1 MULTIPOLYGON (((-93.4007 45...\n2 MULTIPOLYGON (((-93.76753 4...\n3 MULTIPOLYGON (((-94.50614 4...\n4 MULTIPOLYGON (((-94.02525 4...\n5 MULTIPOLYGON (((-96.06762 4...\n6 MULTIPOLYGON (((-93.2277 45...\n7 MULTIPOLYGON (((-96.45332 4...\n8 MULTIPOLYGON (((-97.22904 4...\n\n\n\n# Create Color Palette for 2022 \npal_2022 &lt;- colorNumeric(palette = c(\"red\", \"blue\"), domain = mn_cd_with_results$democratic_2022)\n\n# Map for 2022 Election Results\nleaflet(mn_cd_with_results) |&gt; \n  addTiles() |&gt; \n  addPolygons(\n    fillColor = ~pal_2022(dfl_2022),  # Function needs to be called on the variable\n    fillOpacity = 1,\n    color = \"black\",\n    weight = 1) |&gt; \n  addLegend(\n    pal = pal_2022,\n    values = ~dfl_2022,\n    title = \"Democratic Voteshare (2022)\",\n    position = \"bottomright\")\n\n\n\n\n\n\n# Create Color Palette for 2024\npal_2024 &lt;- colorNumeric(palette = c(\"red\", \"blue\"), domain = mn_cd_with_results$democratic_2022)\n\n# Map for 2024 Election Results\nleaflet(mn_cd_with_results) |&gt; \n  addTiles() |&gt; \n  addPolygons(\n    fillColor = ~pal_2024(dfl_2024),\n    fillOpacity = 1,\n    color = \"black\",\n    weight = 1) |&gt; \n  addLegend(\n    pal = pal_2024,\n    values = ~dfl_2024,\n    title = \"Democratic Voteshare (2024)\",\n    position = \"bottomright\")\n\n\n\n\n\n\n# Calculate the Change in Voteshare (Between 2022 and 2024)\nmn_cd_with_results_1 &lt;- mn_cd_with_results |&gt;\n  mutate(\n    democratic_change = dfl_2024 - dfl_2022,\n    republican_change = r_2024 - r_2022)\n\nmn_cd_with_results_1\n\nSimple feature collection with 8 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -97.22904 ymin: 43.49952 xmax: -89.48923 ymax: 49.38436\nGeodetic CRS:  NAD83\n  STATEFP CD118FP      AFFGEOID GEOID                 NAMELSAD LSAD CDSESSN\n1      27      05 5001800US2705  2705 Congressional District 5   C2     118\n2      27      03 5001800US2703  2703 Congressional District 3   C2     118\n3      27      06 5001800US2706  2706 Congressional District 6   C2     118\n4      27      02 5001800US2702  2702 Congressional District 2   C2     118\n5      27      08 5001800US2708  2708 Congressional District 8   C2     118\n6      27      04 5001800US2704  2704 Congressional District 4   C2     118\n7      27      01 5001800US2701  2701 Congressional District 1   C2     118\n8      27      07 5001800US2707  2707 Congressional District 7   C2     118\n        ALAND      AWATER r_2022 dfl_2022 dfl_2024 r_2024\n1   338801630    16523525  24.53    74.33    74.37  24.56\n2  1212366766   126629346  40.37    59.56    58.43  41.45\n3  6434599477   338776646  61.97    37.79    37.42  62.45\n4  4474617907   212911547  45.65    50.87    55.53  42.08\n5 80910616387 15048680132  57.18    42.72    41.92  57.99\n6   785198132    79844458  32.26    67.59    67.25  32.58\n7 31696870236   561074371  53.83    42.31    41.41  58.51\n8 80391767022  2552744290  66.95    27.61    29.44  70.45\n                        geometry democratic_change republican_change\n1 MULTIPOLYGON (((-93.4007 45...              0.04              0.03\n2 MULTIPOLYGON (((-93.76753 4...             -1.13              1.08\n3 MULTIPOLYGON (((-94.50614 4...             -0.37              0.48\n4 MULTIPOLYGON (((-94.02525 4...              4.66             -3.57\n5 MULTIPOLYGON (((-96.06762 4...             -0.80              0.81\n6 MULTIPOLYGON (((-93.2277 45...             -0.34              0.32\n7 MULTIPOLYGON (((-96.45332 4...             -0.90              4.68\n8 MULTIPOLYGON (((-97.22904 4...              1.83              3.50\n\n\n\n# Map for Democratic Voteshare change\nplot_dem_change &lt;- ggplot(mn_cd_with_results_1) +\n  geom_sf(aes(fill = democratic_change), color = \"black\") +\n  scale_fill_gradient2(\n    low = \"red\",\n    mid = \"white\",\n    high = \"blue\",\n    midpoint = 0,\n    name = \"Dem. Change\\n(2022 - 2024)\") +\n  labs(\n    title = \"Change in Democratic Voteshare (2022 to 2024)\",\n    caption = \"Soure: Minnesota Secretary of States Office\") +\n  theme_minimal()\n\nplot_dem_change\n\n\n\n\n\n9 Reflection:\nThe map offers several insightful observations about the shifts in Democratic voteshare between the 2022 midterm elections and the 2024 elections. Notably, Minnesota’s 2nd Congressional District experienced a significant shift in favor of Democratic candidate Angie Craig. This district has long been considered a swing district, but in 2024, Craig secured a commanding victory, greatly surpassing her 2022 performance and outperforming other Democrats in the state. Additionally, while Minnesota’s 7th District remains a heavily Republican area, it did shift slightly to the left. Most other districts showed moderate shifts to the right, consistent with national trends. Interestingly, Minnesota’s 5th District, the most Democratic in the state, showed no change between the two election cycles.\nThese shifts provide valuable insights into where Democratic candidates gained or lost support in 2024 and open the door to several important research questions. What campaign strategies, narratives, or tactics did certain candidates employ that may have contributed to their increased support? What role did money play in the outcome? These are all compelling questions that warrant further exploration by political scientists and data scientists alike."
  },
  {
    "objectID": "ica/ica-uni.html",
    "href": "ica/ica-uni.html",
    "title": "\n9  Univariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the univariate viz in-class activity. Refer to the class website for details.\n\n# Exercise 1\n# Import data \nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\nhead(hikes)\n\n             peak elevation difficulty ascent length time    rating\n1     Mt. Marcy        5344          5   3166   14.8 10.0  moderate\n2 Algonquin Peak       5114          5   2936    9.6  9.0  moderate\n3   Mt. Haystack       4960          7   3570   17.8 12.0 difficult\n4   Mt. Skylight       4926          7   4265   17.9 15.0 difficult\n5 Whiteface Mtn.       4867          4   2535   10.4  8.5      easy\n6       Dix Mtn.       4857          5   2800   13.2 10.0  moderate\n\n\nA. What features would we like a visualization of the categorical difficulty rating variable to capture? We may want a histogram to help us understand the relative difficulty of each of the hikes and understand relationships between difficulty and other variables.\nB. What about a visualization of the quantitative elevation variable? We would want to see clearly which mountains have higher elevation, and how that variable corresponds to the others, such as difficulty, ascent, etc.\n\n# Use the ggplot function\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nggplot(hikes, aes(x = rating))\n\n\n\n\nHow many hikes fall into each category? 1 easy, 3 are maderate, and 4 are difficult\nAre the hikes evenly distributed among these categories, or are some more common than others? Some are more common than others. They all have different frequencies.\nWhat did this do? What do you observe? It created an empty bar graph that categorizes the hikes as difficult, easy, or moderate along the x axis, and the frequency of the hikes in the dataset along the y axis.\nWhat, in general, is the first argument of the ggplot() function? Hikes\nWhat is the purpose of writing x = rating? It clearly communicates what the different categories on the x axis represent.\nWhat do you think aes stands for?!? aesthetic\n\n# COMMENT on the change in the code and the corresponding change in the plot --- It added bars in gray that visually represents the frequency of each of the categories in the data set of hikes. \nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n# COMMENT on the change in the code and the corresponding change in the plot -- this adds clear labels to the y axis that make the visualization better and easier to understand \nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n# COMMENT on the change in the code and the corresponding change in the plot --- This changed the color of the bars to blue \nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n# COMMENT on the change in the code and the corresponding change in the plot --- this code gave the bars an orange outline (Go Scots!)\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n# COMMENT on the change in the code and the corresponding change in the plot --- this code made the background clearer. \nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") +\n  theme_minimal()\n\n\n\n\n\n9.0.1 Part A: Questions\nReflect on the ggplot() code: The code ultimately generated a compelling and clear data visualization. The clear labeling and engaging coloring make this a great visual representation of the frequency and difficulty rating of the hikes in the data set.\nWhat’s the purpose of the +? When do we use it? The + is used to add layers, aesthetics, and other components to a ggplot object. It helps build plots step by step by connecting different commands.\nWe added the bars using geom_bar()? Why “geom”? The “geom” function creates the clear geometric bars for the graph.\nWhat does labs() stand for? It stands for “labels.”\nWhat’s the difference between color and fill? “Color” is the outline/trimming of the bars in the graph, and “fill” is the color that fills the geometric shape.\n\n9.0.2 Part B: Questions\nObserved categories: What categories did we observe? We can see three categories, namely “Easy”, “Moderate”, and “Difficult”\nVariability between categories: Are observations evenly spread out among the categories, or are some categories more common than others? No they are not evenly spread out. There are more “moderate” hikes represented in the dataset.\nSummarize below what you learned from the bar chart, in context. We learned that there is a significantly higher number of “moderate” hikes in the Adirondacks, compared to less “easy” hikes and even fewere “difficult” hikes. Most of the terrain falls outsides of the extremes of difficulty (easy, difficult).\n\n9.0.3 Part C: Questions\nIs there anything you don’t like about this barplot? I would prefer that the order of the categories be more clear. I’d order it (easy, then moderate, and difficult) This would better capture that the most of the hikes fall in the middle of the x-axis, which represents the level of difficulty."
  },
  {
    "objectID": "ica/ica-bi.html",
    "href": "ica/ica-bi.html",
    "title": "\n10  Bivariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the bivariate viz in-class activity. Refer to the class website for details.\n\n# Load data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n# Check it out\nhead(elections)\n\n  state_name state_abbr historical    county_name county_fips total_votes_20\n1    Alabama         AL        red Autauga County        1001          27770\n2    Alabama         AL        red Baldwin County        1003         109679\n3    Alabama         AL        red Barbour County        1005          10518\n4    Alabama         AL        red    Bibb County        1007           9595\n5    Alabama         AL        red  Blount County        1009          27588\n6    Alabama         AL        red Bullock County        1011           4613\n  repub_pct_20 dem_pct_20 winner_20 total_votes_16 repub_pct_16 dem_pct_16\n1        71.44      27.02     repub          24661        73.44      23.96\n2        76.17      22.41     repub          94090        77.35      19.57\n3        53.45      45.79     repub          10390        52.27      46.66\n4        78.43      20.70     repub           8748        76.97      21.42\n5        89.57       9.57     repub          25384        89.85       8.47\n6        24.84      74.70       dem           4701        24.23      75.09\n  winner_16 total_votes_12 repub_pct_12 dem_pct_12 winner_12 total_population\n1     repub          23909        72.63      26.58     repub            54907\n2     repub          84988        77.39      21.57     repub           187114\n3     repub          11459        48.34      51.25       dem            27321\n4     repub           8391        73.07      26.22     repub            22754\n5     repub          23980        86.49      12.35     repub            57623\n6       dem           5318        23.51      76.31       dem            10746\n  percent_white percent_black percent_asian percent_hispanic per_capita_income\n1            76            18             1                2             24571\n2            83             9             1                4             26766\n3            46            46             0                5             16829\n4            75            22             0                2             17427\n5            88             1             0                8             20730\n6            22            71             0                6             18628\n  median_rent median_age\n1         668       37.5\n2         693       41.5\n3         382       38.3\n4         351       39.4\n5         403       39.6\n6         276       39.6\n\n\nPart A: I guess that the Republican candidate won 73% of counties.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nggplot(elections, aes(x = winner_20)) + geom_bar()\n\n\n\n\n\nggplot(elections, aes(x=repub_pct_20)) + \n  geom_histogram(color = \"white\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_density()\n\n\n\n\n\n# Set up the plotting fram \n# How does this differn than the fram for our histogram of repub_pct_20 alone?\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n\n\n\n# Add a layer of points for each ocunty \n# Take note of the geom! \nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) + \n  geom_point()\n\n\n\n\n\n#Change the shape of the points \n#What happens if you change the shape to another number \nggplot(elections, aes(y=repub_pct_20, x = repub_pct_16)) + \n  geom_point(shape = 3,  color = \"blue\") + geom_text(aes(label = state_abbr)) +  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe relationship between the two variables is positive and linear. This data visualization tells me that for the most part, counties across the U.S. voted similarly in 2016 and 2020. There are a few notable outliers, espcially several counties in Texas.\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n#Scatterplot of repub_pct_20 vs. median_rent \nggplot(elections, aes(y = repub_pct_20, x = median_rent)) + geom_point() + geom_smooth(method = \"lm\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Scatterplot of repub_pct_20 vs median_age\nggplot(elections, aes(y = repub_pct_20, x = median_age)) +\n  geom_point() + geom_smooth(method = \"lm\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n\n\n\n# Boxplots \nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\n\n\n\n\n# The colors used don't match up with the blue, purple, red labels\n# The density plots are on top of each other\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n\n\n\n# scale_fill_manual \"hard codes\" or defines what colors to use for the fill categories\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n# alpha = 0.5 adds transparency\n# the closer alpha is to 0, the more transparent.\n# the closer alpha is to 1, the more opaque.\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n# facet_wrap separates the density plots into \"facets\" for each historical group\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n\n\n\n# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nOne pro of density plots relative to boxplots: doesn’t oversimplify the data / boil the data down to just 5 numbers.\nName one con of density plots relative to boxplots: boxplots can be easier to interpret\n\n# A stacked bar plot\n# historical = x axis / bar categories\n# winner_20 = fills the bars\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n\n\n\n\n# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n\n\n\n# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\n# How do 3pm temperatures (temp3pm) differ by location?\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5)\n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\nggplot(weather, aes(y = temp3pm, x = location)) + \n  geom_boxplot()\n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\nggplot(weather, aes(y = temp3pm, x = temp9am)) + \n  geom_point()\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n# How do the number of rainy days (raintoday) differ by location?\nggplot(weather, aes(x = location, fill = raintoday)) + \n  geom_bar()"
  },
  {
    "objectID": "ica/ica-multi.html",
    "href": "ica/ica-multi.html",
    "title": "\n11  ICA Mulivariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the mulivariate viz in-class activity. Refer to the class website for details.\n\n#Download GGPLOT\nlibrary(ggplot2) \n\n# Import Education Data\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nhead(education)\n\n       State expend ratio salary frac verbal math  sat  fracCat\n1    Alabama  4.405  17.2 31.144    8    491  538 1029   (0,15]\n2     Alaska  8.963  17.6 47.951   47    445  489  934 (45,100]\n3    Arizona  4.778  19.3 32.175   27    448  496  944  (15,45]\n4   Arkansas  4.459  17.1 28.934    6    482  523 1005   (0,15]\n5 California  4.992  24.0 41.078   45    417  485  902  (15,45]\n6   Colorado  5.443  18.4 34.571   29    462  518  980  (15,45]\n\n\n\n# Part A: Create histogram\nggplot(education, aes(x = sat)) + \n  geom_density()\n\n\n\n\nPart B: The average scores are between 800 to 1100. They are bi-modal\n\n# SAT Scores vs Per Pupil Spending\nggplot(education, aes(y = sat, x = expend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n# Plot of SAT Scores vs. Salary\nggplot(education, aes(y = sat, x = salary)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\nPart B: The plot shows that typically, the higher per student spending and teacher salaries, the worse the SAT scores.\n\n# Create plot for SAT Scores vs. Per Student Spending Vs. Teacher Salaries \nggplot(education, aes(y = sat, x = salary, color = expend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n# Exercise 4\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 2))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 3))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\n#Exercise 5, Part A\nggplot(education, aes(x = fracCat)) + \n  geom_bar()\n\n\n\n\n\n#Part B\nggplot(education, aes(x = sat, fill = fracCat)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n#Part c\nggplot(education, aes(y = sat, x = expend, color = fracCat)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n#Exercise 6: Let's Make Some Heat Maps\n\nlibrary(tibble)\n\n#Part A\n# Remove the \"State\" column and use it to label the rows\n# Then scale the variables\nplot_data &lt;- education |&gt; \n  column_to_rownames(\"State\") |&gt; \n  data.matrix() |&gt; \n  scale()\n\n\n#Exercise 7: Create Star Plots\n\n#Part A\nstars(plot_data,\n  flip.labels = FALSE,\n  key.loc = c(10, 1.5),\n  cex = 1, \n  draw.segments = TRUE)\n\n\n\n\n\n#Part B\nstars(plot_data,\n  flip.labels = FALSE,\n  locations = data.matrix(as.data.frame(state.center)),  # added external data to arrange by geo location\n  key.loc = c(-110, 28),\n  cex = 1, \n  draw.segments = TRUE)"
  },
  {
    "objectID": "ica/ica-spatial.html",
    "href": "ica/ica-spatial.html",
    "title": "\n12  Exercise 1: A Leaflet With Markers / Points ###\n",
    "section": "",
    "text": "Use this file for practice with the spatial viz in-class activity. Refer to the class website for details.\n\n\nfave_places &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/our_fave_places.csv\")\n\n# Check it out\nhead(fave_places)\n\n  latitude longitude\n1       59        18\n2       45       -93\n3       33      -117\n4       40       116\n5       40       106\n6       37      -122\n\n\n\n### Part A ###\n\n# Load Leaflet\nlibrary(leaflet)\n\n# Just a plotting frame\nleaflet(data = fave_places)\n\n\n\n\n\n\n# Now what do we have?\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers(lng = ~longitude, lat = ~latitude)\n\n\n\n\n\n\n### Exercise 2: Details ###\n\n# Load package needed to change color\nlibrary(gplots)\n\n# We can add colored circles instead of markers at each location\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addCircles(color = col2hex(\"red\"))\n\n\n\n\n\n\nleaflet(data = fave_places) |&gt;\n  addProviderTiles(\"USGS\") |&gt; # Change the background \n  addCircles(weight = 10, opacity = 1, color = col2hex(\"yellow\")) |&gt; #Mark locations with yellow dots\n  addPolylines(\n    lng = ~longitude,\n    lat = ~latitude,\n    color = col2hex(\"green\")) # Connect the dots with green lines\n\n\n\n\n\n\n### Exercise 3 ###\n\n#Load Libraries\nlibrary(dplyr)\nlibrary(leaflet)\nlibrary(ggplot2)\n\n# Import starbucks location data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\n\n# Filter for Starbucks in Minnesota\nstarbucks_mn &lt;- starbucks |&gt;   \n  filter(Country == \"US\", State.Province == \"MN\")\n\n#Create Leaflet\nleaflet(data = starbucks_mn) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\n\n### Exercise 4 ###\n\n#Part A: First, we can grab country-level boundaries from the rnaturalearth package.\n\n# Load the rnaturalearth package\nlibrary(rnaturalearth)\n\n# Retrieve world country boundaries in \"sf\" (simple features) format\nworld_boundaries &lt;- ne_countries(returnclass = \"sf\")\n\n\n#Part B\n# This code produces a world map showing country boundaries.\n# What geom are we using for the point map? We are using geom_sf() to create the geometric shapes \nggplot(world_boundaries) + \n  geom_sf()\n\n\n\n\n\n# Load package needed to change map theme\nlibrary(mosaic)\n\n# Add a point for each Starbucks\n# NOTE: The Starbucks info is in our starbucks data, not world_boundaries\n# How does this change how we use geom_point?!\nggplot(world_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3, size = 0.2, color = \"darkgreen\") +\n  theme_map()\n\n\n\n\nPart C: The map visually highlights that Starbucks has a strong presence in North America, Europe, and East Asia, a moderate presence in some other regions, and a very limited footprint in Africa.\n\n### Exercise 5: Zooming in on some countries ###\n\n#Part A\nstarbucks_cma &lt;- starbucks |&gt; \n  filter(Country %in% c('CA', 'MX', 'US'))\n\n#A Background Map of State\ncma_boundaries &lt;- ne_states(\n  country = c(\"canada\", \"mexico\", \"united states of america\"),\n  returnclass = \"sf\")\n\n\n#Part B\n# Just the boundaries\nggplot(cma_boundaries) + \n  geom_sf()\n\n\n\n\n\n# Add the points\n# And zoom in\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50)) +\n  theme_map()\n\n\n\n\n\n# Exercise 6: Create a state and county-level map\n\n#Part A\nstarbucks_midwest &lt;- starbucks |&gt; \n  filter(State.Province %in% c(\"MN\", \"ND\", \"SD\", \"WI\"))\n\n# Load packages\nlibrary(sf)\nlibrary(maps)\n\n# Get the boundaries\nmidwest_boundaries &lt;- st_as_sf(\n  maps::map(\"county\",\n            region = c(\"minnesota\", \"wisconsin\", \"north dakota\", \"south dakota\"), \n            fill = TRUE, plot = FALSE))\n\n# Check it out\nhead(midwest_boundaries)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -96.81268 ymin: 45.05167 xmax: -93.01397 ymax: 48.53526\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\n                                     ID                           geom\nminnesota,aitkin       minnesota,aitkin MULTIPOLYGON (((-93.03689 4...\nminnesota,anoka         minnesota,anoka MULTIPOLYGON (((-93.51817 4...\nminnesota,becker       minnesota,becker MULTIPOLYGON (((-95.14537 4...\nminnesota,beltrami   minnesota,beltrami MULTIPOLYGON (((-95.58655 4...\nminnesota,benton       minnesota,benton MULTIPOLYGON (((-93.77027 4...\nminnesota,big stone minnesota,big stone MULTIPOLYGON (((-96.10794 4...\n\n\n\n# Part B\nggplot(midwest_boundaries) +\n  geom_sf() +\n  geom_point(\n    data = starbucks_midwest,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.7,\n    size = 0.2,\n    color = 'darkgreen') +\n  theme_map()\n\n\n\n\n\n### Exercise 7: Contour Maps ###\n\n# Point map (we made this earlier)\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n# What changed in the plot?\n# What changed in our code?!\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_density_2d(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n### PART 3: Choropleth Maps ### \nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n#CODE\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\nExercise 8: State-level choropleth maps\n\n#Part A\n\n# Get the latitude and longitude coordinates of state boundaries\nstates_map &lt;- map_data(\"state\")\n\n# Check it out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\n\n# Part B\n# Note where the dataset, elections_by_state, is used\n# Note where the background map, states_map, is used\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() \n\n\n\n\n\n# Make it nicer!\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_gradientn(name = \"% Republican\", colors = c(\"blue\", \"purple\", \"red\"), values = scales::rescale(seq(0, 100, by = 5)))\n\n\n\n\n\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map()\n\n\n\n\n\n# Load package needed for refining color palette\nlibrary(RColorBrewer)\n\n# Now fix the colors\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n#Part C\n# Get only the starbucks data from the US\nstarbucks_us &lt;- starbucks |&gt; \n  filter(Country == \"US\")\n\n# Map it\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  geom_point(\n    data = starbucks_us,\n    aes(x = Longitude, y = Latitude),\n    size = 0.05,\n    alpha = 0.2,\n    inherit.aes = FALSE\n  ) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\nExercise 9: County-level choropleth maps\n\n#Part A\n# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\n\n# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\n\n#Part B\nggplot(elections_by_counties, aes(map_id = county_fips, fill = repub_20_categories)) +\n  geom_map(map = county_map) +\n  scale_fill_manual(values = rev(brewer.pal(10, \"RdBu\")), name = \"% Republican\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()\n\n\n\n\n\n12.0.1 Spacial Vizualization: Exercise #10\nConstruct county-level maps of median_rent and median_age.\n\n# Download Datasets\nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n# Wrangle the Data\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\n\n# Get Latitude and Longitude Coordinates of States\nstates_map &lt;- map_data(\"state\")\n\n# Check It Out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\n\n# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\n\n# Create A County-Level Map of median_rent \nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal() + \n  scale_fill_gradientn(name = \"median rent\", colors = c(\"white\", \"lightgreen\", \"darkgreen\"))"
  }
]