[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMP/STAT112 Notebook",
    "section": "",
    "text": "Welcome\nWelcome to my online portfolio for COMP/STAT112 course taken at Macalester College. Please, use the side bar on the left for navigation."
  },
  {
    "objectID": "bw/bw-uni.html",
    "href": "bw/bw-uni.html",
    "title": "\n1  Univariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking univariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nCode### UNIVARIATE VIZUALIZATION ###\n\n# Import Data \nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\n\n# Download Tidyverse\nlibrary(tidyverse)\n\n#Reorder Rating\nhikes$rating &lt;- factor(hikes$rating, levels = c(\"easy\", \"moderate\", \"difficult\"))\n\n# Create Univariate Visualization with improvements\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"darkblue\", fill = \"skyblue\", width = 0.8) +              # Adjust colors and width\n  labs(\n    title = \"Distribution of Hike Ratings\",                                   # Add title\n    x = \"Hike Rating\",                                                        # Label x-axis\n    y = \"Frequency of Hikes\",                                                 # Label y-axis\n    caption = \"Source: Serhiy Mytrovtsiy, 2020\") +                            # Add source info\n  theme_minimal() +                                                           # Clean background\n  theme(plot.title = element_text(face = \"bold\", size = 15, hjust = 0.5),     # Make the title bold\n        plot.caption = element_text(size = 10),                               # Adjust size of  caption \n        panel.grid.major = element_line(color = \"gray80\"))                    # Adjust grid lines"
  },
  {
    "objectID": "bw/bw-bi.html",
    "href": "bw/bw-bi.html",
    "title": "\n2  Bivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking bivariate visualization. The visualization will not perfect the first time but you are expected to improve it throughout the semester especially after covering advanced topics such as effective viz.\n\nCode### BIVARIATE VISUALIZATION ###\n\n# Load GGPLOT \nlibrary(ggplot2)\n\n# Load Data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n# Create Plot\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.55) +                                          # Add transparency\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"),                 # Add partisan colors                 \n                     name = \"Historical Voting Pattern\",                 # Added title to the legend\n                     labels = c(\"Democrat\", \"Swing\", \"Republican\")) +    # Add labels \n  labs(\n    title = \"Density Plot of Republican Vote Share in 2020 by Historical Vote\",\n    x = \"Republican Vote Percentage (2020)\",\n    y = \"Density\",\n    caption = \"Source: Danny Kaplan, 2021\"                             # Add source info\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15, hjust = 0.5),  # Make title centered and bold \n    legend.position = \"bottom\",                                        # Place legend at the bottom\n    plot.caption = element_text(size = 10),                            # Adjust size of caption  \n    panel.grid.major = element_line(color = \"gray80\"))                 # Adjust grid lines"
  },
  {
    "objectID": "bw/bw-tri.html",
    "href": "bw/bw-tri.html",
    "title": "\n3  Trivariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking trivariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nCode# Import Education Data\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nhead(education)\n\n       State expend ratio salary frac verbal math  sat  fracCat\n1    Alabama  4.405  17.2 31.144    8    491  538 1029   (0,15]\n2     Alaska  8.963  17.6 47.951   47    445  489  934 (45,100]\n3    Arizona  4.778  19.3 32.175   27    448  496  944  (15,45]\n4   Arkansas  4.459  17.1 28.934    6    482  523 1005   (0,15]\n5 California  4.992  24.0 41.078   45    417  485  902  (15,45]\n6   Colorado  5.443  18.4 34.571   29    462  518  980  (15,45]\n\n\n\nCode# Download Library \nlibrary(ggplot2)\n\n# Create Density Plot\nggplot(education, aes(x = sat, fill = fracCat)) + \n  geom_density(alpha = 0.6) +                                                # Adjust Transparency \n  labs(\n    title = \"SAT Score Distributions by Student Participation Rate\",\n    x = \"SAT Total Score\",\n    y = \"Density\",\n    caption = \"Source: College Board (compiled by Danny Kaplan, 2021)\",\n    fill = \"SAT Participation Rate (%)\") +\n  theme_minimal() +                                                           # Cleaner theme\n  theme(\n    plot.title = element_text(face = \"bold\", size = 15, hjust = 0.5),         # Make Title Bold and Centered\n    plot.caption = element_text(size = 10, hjust = 0.5),                      # Adjust size of caption\n    panel.grid.major = element_line(color = \"gray80\"),                        # Adjust grid lines\n    legend.position = \"right\")                                                # Position the Legend on the right\n\n\n\n\n\n4 Reflection\nThis visualization demonstrates the relationship between three variables related to education and SAT scores across different states.\n\nThe x-axis represents student’s combined score of the verbal and math sections of the SAT. Higher values indicate better overall performance on the SAT.\nThe y-axis shows shows the probability density of the SAT scores within each category of fracCat. In other words, the height of the curves at any given SAT score shows how concentrated the scores are for states within that fracCat group.\nThe Color/Fill displays the fracCat (Proportion of Students Taking the SAT). This is the third variable, categorized into three groups: States where a very small proportion (0 to 15%) took the SAT; States where a moderate proportion (between 15% and 45%) took the SAT; and States where a high proportion (greater than 45% up to 100%) took the SAT.\n\nThe most striking takeaway is the clear inverse relationship between the fraction of students taking the SAT and the overall distribution of SAT scores in a state. In states with low participation, the average scores tend to be inflated. Conversely, in states with much higher participation, the average scores tend to be lower.\n\nCode# Create A Scatter Plot with Linear Regression Lines\nlibrary(ggplot2)\nggplot(education, aes(x = expend, y = sat, color = fracCat)) +\n  geom_point(alpha = 0.7, size = 3) +                                         #Adjust Transparency and Point Size\n  geom_smooth(method = \"lm\", se = TRUE, linewidth = 1) +                      # Keep regression lines with confidence intervals\n  labs(\n    title = \"Expenditure Per Student and SAT Scores by Participation Rate\",\n    x = \"Expenditure Per Student\",\n    y = \"SAT Total Score\",\n    caption = \"Source: College Board (compiled by Danny Kaplan, 2021)\",\n    color = \"SAT Participation Rate\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 12, hjust = 0.5),         # Make Title Bold and Centered\n    plot.caption = element_text(size = 10, hjust = 0.5),                      # Adjust size of caption\n    panel.grid.major = element_line(color = \"gray80\"),                        # Adjust grid lines\n    legend.position = \"right\")                                                # Position the Legend on the right\n\n\n\n\n\n5 Reflection\nThis Scatter Plot displays the relationship between two numerical variables, Expenditure Per Student (on the x-axis) and SAT Total Score (on the y-axis). The third variable, SAT Participation Rate, is introduced through the color of the data points and the separate linear regression lines.This trivariate visualization demonstrates that the proportion of students taking the SAT seems to be a stronger predictor of average SAT scores than expenditure per student. States with lower SAT participation rates tend to have higher average scores, regardless of their spending per student. Conversely, states with high participation rates tend to have lower average scores."
  },
  {
    "objectID": "bw/bw-quad.html",
    "href": "bw/bw-quad.html",
    "title": "\n4  Quadvariate Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking quadvariate visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\nCode# Load Necessary Libraries\nlibrary(tidyverse)\nlibrary(fivethirtyeight)\nlibrary(ggplot2)\n\n# Create `new_bechdel` Dataset\nnew_bechdel &lt;- bechdel |&gt;\n  mutate(clean_test = factor(clean_test, c(\"nowomen\", \"notalk\", \"men\", \"dubious\", \"ok\"))) |&gt;\n  mutate(half_decades = cut(year, breaks = seq(1969, 2014, by = 5)))\n\n\n\nCode# Create Quadvariate Vizualization \n\nggplot(new_bechdel, aes(x = budget, y = domgross, color = binary)) +\n  geom_point(alpha = 0.7, size = 0.5) +\n  geom_smooth(method = \"lm\") + \n  facet_wrap(~ clean_test,  labeller = labeller(clean_test = c(\"nowomen\" = \"No Women\",\n                                                \"notalk\" = \"No Talk\",\n                                                \"men\" = \"Men Only\",\n                                                \"dubious\" = \"Dubious\",\n                                                \"ok\" = \"Passes\")),\n             ncol = 3, # Specify the number of columns for the facets\n             scales = \"free_x\") + # Allow x-axis scales to vary if needed +\n   labs(\n    title = \"Bechdel Test Results by Reason for Failure\",\n    x = \"Budget (in USD)\",\n    y = \"Domestic Gross (in USD)\",\n    caption = \"Source: Walt Hickey, 'The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women,' FiveThirtyEight, 2014\",\n    color = \"Bechdel Test Result\") +\n  theme_minimal() + \n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 16),\n    axis.title.x = element_text(face = \"bold\", size = 12),\n    axis.title.y = element_text(face = \"bold\", size = 12),\n    legend.title = element_text(face = \"bold\", size = 12),\n    strip.text = element_text(face = \"bold\", size = 11),\n    plot.caption = element_text(size = 8, hjust = 0.5), \n    panel.spacing.x = unit(1, \"cm\"),\n    panel.spacing.y = unit(1, \"cm\"), \n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10), \n    axis.text.y = element_text(size = 10),\n    plot.margin = margin(1, 1, 1, 1, \"cm\"))"
  },
  {
    "objectID": "bw/bw-spatial.html",
    "href": "bw/bw-spatial.html",
    "title": "\n5  Spatial Viz\n",
    "section": "",
    "text": "Use this file to generate a professional looking spatial visualization. The visualization will not perfect the first time but you are expected to improve on it throughout the semester especially after covering advanced topics such as effective viz.\n\n5.0.1 Spacial Vizualization: Exercise #10\nConstruct county-level maps of median_rent and median_age.\n\nCode#Load Libraries \nlibrary(leaflet)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n\nCode# Download Datasets\nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n\nCode# Wrangle the Data\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\n\n\nCode# Get Latitude and Longitude Coordinates of States\nstates_map &lt;- map_data(\"state\")\n\n# Check It Out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\n\nCode# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\n\nCode# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\n\n\nCode# Create A County-Level Map of median_rent \nlibrary(ggplot2)\nlibrary(viridis) # For better color palettes\n\nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n    geom_map(map = county_map) +\n    expand_limits(x = county_map$long, y = county_map$lat) +\n    coord_equal() +\n    scale_fill_viridis_c(name = \"Median Monthly Rent ($)\", option = \"magma\") + # Using a viridis palette\n    theme_void() + # Cleaner background\n    theme(legend.position = \"right\",\n          plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"), # Centered, larger title\n          plot.subtitle = element_text(hjust = 0.5, size = 12), # Centered subtitle\n          plot.caption = element_text(hjust = 0.5, size = 10, color = \"black\")) + # Left-aligned caption\n    labs(title = \"Median Rent by County in the United States\",\n         subtitle = \"Estimated for 2020\",\n         caption = \"Source: Federal Election Commission (2020)\")\n\n\n\n\nThe “Median Rent by County in the United States’ visualization helps us understand the spatial patterns of median monthly rent across the United States at the county level in 2020. It highlights regional disparities and the influence of living in a coastal and/or metropolitan areas on housing costs. The lightest areas on the map, representing the highest median monthly rents, are predominantly concentrated along the coasts. Additionally, major inland metropolitan areas, such as Chicago, Denver, and Dallas, also exhibit higher median rents compared to their surrounding areas.\nNote On Missing Data: It’s important to note that there are some counties that appear black on the map, indicating missing data for the median rent in those specific counties for the year 2020."
  },
  {
    "objectID": "bw/Exam-one.html",
    "href": "bw/Exam-one.html",
    "title": "\n6  Exam 1\n",
    "section": "",
    "text": "Code#Download Food Consumption and CO2 Emissions Dataset\nfood_consumption &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-18/food_consumption.csv')\n\nfood_consumption\n\n# A tibble: 1,430 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 1,420 more rows\n\n\nUsing an appropriate viz, you need to answer the following grand research question: What does the consumption of each food category in each country look like?\n\nCode# Install Packages \nlibrary(tidytuesdayR)\nlibrary(tidyverse)\n\n\n\nCode# Get Data\ntuesdata &lt;- tt_load('2020-02-18')\nfc &lt;- tuesdata$food_consumption \n\n\n\nCode# Understand Data - List some initial steps that should be carried after loading the above dataset\nhead(fc)\n\n# A tibble: 6 × 4\n  country   food_category consumption co2_emmission\n  &lt;chr&gt;     &lt;chr&gt;               &lt;dbl&gt;         &lt;dbl&gt;\n1 Argentina Pork                10.5          37.2 \n2 Argentina Poultry             38.7          41.5 \n3 Argentina Beef                55.5        1712   \n4 Argentina Lamb & Goat          1.56         54.6 \n5 Argentina Fish                 4.36          6.96\n6 Argentina Eggs                11.4          10.5 \n\nCodenrow(fc)\n\n[1] 1430\n\nCodedim(fc)\n\n[1] 1430    4\n\nCodestr(fc)\n\nspc_tbl_ [1,430 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ country      : chr [1:1430] \"Argentina\" \"Argentina\" \"Argentina\" \"Argentina\" ...\n $ food_category: chr [1:1430] \"Pork\" \"Poultry\" \"Beef\" \"Lamb & Goat\" ...\n $ consumption  : num [1:1430] 10.51 38.66 55.48 1.56 4.36 ...\n $ co2_emmission: num [1:1430] 37.2 41.53 1712 54.63 6.96 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   country = col_character(),\n  ..   food_category = col_character(),\n  ..   consumption = col_double(),\n  ..   co2_emmission = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nWhat are the units of observations?\nUnits: Country, Food, Category\nThere are 11 Food Categories.\nThere are 130 Countries.\n\nCode# Grouped By Bar Plot (Faceted by Food Category)\n\nggplot(food_consumption, aes(x = country, y = consumption)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") + \n  facet_wrap(~ food_category, scales = \"free_y\") +\n  labs(\n    title = \"Consumption of Food Categories Across Countries\",\n    x = \"Country\",\n    y = \"Consumption\"\n  ) +\n  theme_bw() +  \n  theme(axis.text.x = element_blank(),\n        axis.ticks.x = element_blank()) \n\n\n\n\nI decided to try doing a Bar Chart Faceted by Food Category. Essentially, for each food category (faceted), you have a 11 bar charts (one per food category) where the y-axis represents countries and the x-axis represents consumption. Within each chart, you have bars for each 130 countries. This type of visualization is good for sing the diversity of consumption levels across the world. However, with 130 countries (130 bars) it makes it difficult to interpret each of the individual values and identify any particular country. If the visualization was interactive, where one could zoom in and out - that may improve it and make it more legible. While not the perfect Viz, I do think this is very useful way to display the data. In Exam #2, we take this research question further and use spatial data to create 11 maps showing the levels of consumption across the world for each of the 11 food categories."
  },
  {
    "objectID": "bw/Exam-two.html",
    "href": "bw/Exam-two.html",
    "title": "\n7  Exam 2\n",
    "section": "",
    "text": "Code#Download Food Consumption and CO2 Emissions Dataset\nfood_consumption &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-18/food_consumption.csv')\n\n# Install via pak::pak(\"dslc-io/tidytuesdayR\")\n\ntuesdata &lt;- tidytuesdayR::tt_load('2020-02-18')\ntuesdata &lt;- tidytuesdayR::tt_load(2020, week = 8)\n\n\nfood_consumption &lt;- tuesdata$food_consumption\n\n\n\nCode# 2.1 Data Dictionary (View Data)\nfood_consumption\n\n# A tibble: 1,430 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 1,420 more rows\n\n\n\nCode# 2.2 Load Packages/Libraries\nlibrary(tidytuesdayR)\nlibrary(tidyverse)\nlibrary(rnaturalearth)  # for country boundaries \nlibrary(sf)             # for spatial viz \nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n\nCode# 2.3 Load Data \ntuesdata &lt;- tt_load('2020-02-18')\nfc &lt;- tuesdata$food_consumption\n\n\n\nCode# 2.4 Inspect Data \nstr(fc)\n\nspc_tbl_ [1,430 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ country      : chr [1:1430] \"Argentina\" \"Argentina\" \"Argentina\" \"Argentina\" ...\n $ food_category: chr [1:1430] \"Pork\" \"Poultry\" \"Beef\" \"Lamb & Goat\" ...\n $ consumption  : num [1:1430] 10.51 38.66 55.48 1.56 4.36 ...\n $ co2_emmission: num [1:1430] 37.2 41.53 1712 54.63 6.96 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   country = col_character(),\n  ..   food_category = col_character(),\n  ..   consumption = col_double(),\n  ..   co2_emmission = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nCodehead (fc, 22)\n\n# A tibble: 22 × 4\n   country   food_category            consumption co2_emmission\n   &lt;chr&gt;     &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;\n 1 Argentina Pork                           10.5          37.2 \n 2 Argentina Poultry                        38.7          41.5 \n 3 Argentina Beef                           55.5        1712   \n 4 Argentina Lamb & Goat                     1.56         54.6 \n 5 Argentina Fish                            4.36          6.96\n 6 Argentina Eggs                           11.4          10.5 \n 7 Argentina Milk - inc. cheese            195.          278.  \n 8 Argentina Wheat and Wheat Products      103.           19.7 \n 9 Argentina Rice                            8.77         11.2 \n10 Argentina Soybeans                        0             0   \n# ℹ 12 more rows\n\n\n\nCode# 2.7 Fix food_category Variable \nfcc &lt;- food_consumption |&gt; \n  mutate(food_category = fct_recode(food_category,\n  \"Lamb\" = \"Lamb & Goat\",\n  \"Dairy\" = \"Milk - inc. cheese\",\n  \"Wheat\" = \"Wheat and Wheat Products\",\n  \"Nuts\" = \"Nuts inc. Peanut Butter\"))\n\nfcc$food_category #2.8 make sure the new values of food_category variable are as expected \n\n   [1] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n   [9] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n  [17] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n  [25] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n  [33] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n  [41] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n  [49] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n  [57] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n  [65] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n  [73] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n  [81] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n  [89] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n  [97] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [105] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [113] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [121] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [129] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [137] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [145] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [153] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [161] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [169] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [177] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [185] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [193] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [201] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [209] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [217] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [225] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [233] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [241] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [249] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [257] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [265] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [273] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [281] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [289] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [297] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [305] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [313] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [321] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [329] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [337] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [345] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [353] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [361] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [369] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [377] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [385] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [393] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [401] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [409] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [417] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [425] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [433] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [441] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [449] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [457] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [465] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [473] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [481] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [489] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [497] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [505] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [513] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [521] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [529] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [537] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [545] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [553] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [561] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [569] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [577] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [585] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [593] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [601] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [609] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [617] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [625] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [633] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [641] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [649] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [657] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [665] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [673] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [681] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [689] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [697] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [705] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [713] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [721] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [729] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [737] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [745] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [753] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [761] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [769] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [777] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [785] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [793] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [801] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [809] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [817] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [825] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [833] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [841] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [849] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [857] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [865] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [873] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [881] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [889] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [897] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [905] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n [913] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n [921] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n [929] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n [937] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n [945] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n [953] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n [961] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n [969] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n [977] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n [985] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n [993] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1001] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1009] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1017] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1025] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1033] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1041] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1049] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1057] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1065] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1073] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n[1081] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1089] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1097] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1105] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1113] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1121] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1129] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1137] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1145] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1153] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1161] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n[1169] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1177] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1185] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1193] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1201] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1209] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1217] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1225] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1233] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1241] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1249] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n[1257] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1265] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1273] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1281] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1289] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1297] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1305] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1313] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1321] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1329] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1337] Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry \n[1345] Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans\n[1353] Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy   \n[1361] Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb    \n[1369] Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts     Pork    \n[1377] Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat    Rice    \n[1385] Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish     Eggs    \n[1393] Dairy    Wheat    Rice     Soybeans Nuts     Pork     Poultry  Beef    \n[1401] Lamb     Fish     Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \n[1409] Pork     Poultry  Beef     Lamb     Fish     Eggs     Dairy    Wheat   \n[1417] Rice     Soybeans Nuts     Pork     Poultry  Beef     Lamb     Fish    \n[1425] Eggs     Dairy    Wheat    Rice     Soybeans Nuts    \nLevels: Beef Eggs Fish Lamb Dairy Nuts Pork Poultry Rice Soybeans Wheat\n\n\n\nCode# 3 - Which 5 countries consume the most food?\ntop_five_countries &lt;- fcc |&gt;\n  group_by(country) |&gt;\n  summarize(consumption = sum(consumption)) |&gt;\n  arrange(desc(consumption)) |&gt;\n  head(5)\n\ntop_five_countries\n\n# A tibble: 5 × 2\n  country     consumption\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Finland            640.\n2 Lithuania          555.\n3 Sweden             550 \n4 Netherlands        534.\n5 Albania            533.\n\n\n\nCode# Make The Plot \nggplot(top_five_countries, aes(x = reorder(country, consumption), y = consumption)) +\n  geom_col(fill = \"steelblue\") +\n  labs(\n    title = \"Top 5 Countries by Total Food Consumption\",\n    x = \"Country\",\n    y = \"Consumption\") +\n  theme_minimal()\n\n\n\n\n\nCode# 4 - Which Top 5 Countries Consume Each Food?\n\n#Find The Top Five Countries By Consumption For Each Food Category \ntop_five_per_food &lt;- fcc |&gt;\n  group_by(food_category, country) |&gt;\n  summarize(consumption = sum(consumption), .groups = \"drop\") |&gt;\n  arrange(food_category, desc(consumption)) |&gt;\n  group_by(food_category) |&gt;\n  slice_head(n = 5)\n\n\n\nCode#Plot The Visualization Using geom_col and facet_wrap\nggplot(top_five_per_food, aes(x = reorder(country, consumption), y = consumption)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = round(consumption, 1)), hjust = -0.1, size = 3) +  # Adjusted hjust for spacing\n  facet_wrap(~ food_category, scales = \"free_y\", ncol = 2) +  # Changed scales to \"free_y\"\n  coord_flip() +\n  labs(\n    title = \"Top 5 Countries by Consumption for Each Food Category\",\n    x = \"Country\",\n    y = \"Consumption (kg/person/year)\" ) +\n  theme_minimal() \n\n\n\n\n\nCode# 5 - What does the consumption of each food look like? \n\n#Attempt 3\nne_countries(returnclass = \"sf\") |&gt;\n  select(name, geometry) |&gt;\n  mutate(name = ifelse(name == \"United States of America\", \"USA\", name)) |&gt;\n  mutate(name = ifelse(name == \"Bosnia and Herz.\", \"Bosnia and Herzegovina\", name)) |&gt;\n  mutate(name = ifelse(name == \"Czechia\", \"Czech Republic\", name)) |&gt;\n  mutate(name = ifelse(name == \"Taiwan\", \"Taiwan. ROC\", name)) |&gt;\n  left_join(\n    fcc |&gt;\n      select(-co2_emmission) |&gt;\n      group_by(food_category) |&gt;\n      mutate(consumption = (consumption - mean(consumption))/sd(consumption)), join_by(name == country)) |&gt;\n  pivot_wider(names_from = food_category, values_from = consumption) |&gt;\n  select(-\"NA\") |&gt;\n  pivot_longer(cols = c(-name, -geometry), \n               names_to = \"food_category\", \n               values_to = \"consumption\") |&gt;\n  ggplot() + \n  geom_sf(aes(fill = consumption)) + \n  facet_wrap(~food_category, ncol = 4) + \n  scale_fill_viridis_c(option = \"plasma\", na.value = \"white\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 14),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(size = 10))"
  },
  {
    "objectID": "bw/SoloProject.html",
    "href": "bw/SoloProject.html",
    "title": "\n8  Solo Project\n",
    "section": "",
    "text": "For my solo project, I wanted to visualize the shifts in Democratic voteshare across Minnesota’s eight congressional districts between the 2022 midterm elections and the 2024 general election. This project involved collecting certified election results from both cycles, calculating the change in Democratic voteshare, and displaying those shifts through a comparative visual format.\n\nCode# Load Necessary Libraries\nlibrary(tigris)\nlibrary(leaflet)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(stringr)\n\n# Load United States Congressional Districts\ncd118 &lt;- congressional_districts(cb = TRUE, resolution = \"20m\", year = 2022)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |                                                                      |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |==========================                                            |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |======================================================================| 100%\n\nCode# Create Map\nleaflet(cd118) |&gt;\n  addTiles() |&gt;\n  addPolygons()\n\n\n\n\n\n\nCode# Define Minnesota Congressional Districts\nmn_cd &lt;- congressional_districts(state = \"MN\", cb = TRUE, resolution = \"20m\", year = 2022)\n\n# Create Map\nleaflet(mn_cd) |&gt;\n  addTiles() |&gt;\n  addPolygons(\n    label = ~paste(\"District\", CD118FP),)\n\n\n\n\n\n\nCode#Import 2022 Minnesota Congressional Results \ndata_2022 &lt;- read_delim(\"../data/Election_Results_2022\", col_names = FALSE)\n\n# Clean and filter data\nMinnesota_Congressional_Results_2022 &lt;- data_2022 |&gt;\n  select(X6, X11, X15) |&gt;\n  rename(District = X6,\n         Party = X11,\n         Voteshare = X15) |&gt;\n  filter(Party %in% c(\"DFL\", \"R\"))  # Filter for DFL and R parties\n\nMinnesota_Congressional_Results_2022\n\n# A tibble: 16 × 3\n   District Party Voteshare\n      &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        1 R          53.8\n 2        1 DFL        42.3\n 3        2 R          45.6\n 4        2 DFL        50.9\n 5        3 R          40.4\n 6        3 DFL        59.6\n 7        4 R          32.3\n 8        4 DFL        67.6\n 9        5 R          24.5\n10        5 DFL        74.3\n11        6 R          62.0\n12        6 DFL        37.8\n13        7 R          67.0\n14        7 DFL        27.6\n15        8 R          57.2\n16        8 DFL        42.7\n\n\n\nCode#Import 2024 Minnesota Congressional Results \ndata_2024 &lt;- read_delim(\"../data/Election_Results_2024\", col_names = FALSE)\n\nMinnesota_Congressional_Results_2024 &lt;- data_2024 |&gt;\n  select(X6, X11, X15) |&gt;\n  rename(District = X6,\n         Party = X11,\n         Voteshare = X15)  |&gt;\n  filter(Party %in% c(\"DFL\", \"R\"))  # Keep only DFL and R parties \n\nMinnesota_Congressional_Results_2024\n\n# A tibble: 16 × 3\n   District Party Voteshare\n      &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1        1 DFL        41.4\n 2        1 R          58.5\n 3        2 R          42.1\n 4        2 DFL        55.5\n 5        3 DFL        58.4\n 6        3 R          41.4\n 7        4 R          32.6\n 8        4 DFL        67.2\n 9        5 R          24.6\n10        5 DFL        74.4\n11        6 R          62.4\n12        6 DFL        37.4\n13        7 DFL        29.4\n14        7 R          70.4\n15        8 DFL        41.9\n16        8 R          58.0\n\n\n\nCode#Combine 2022 and 2024 Data\nMinnesota_Congressional_Results_2022 &lt;- Minnesota_Congressional_Results_2022 |&gt;\n  mutate(Year = 2022)\n\nMinnesota_Congressional_Results_2024 &lt;- Minnesota_Congressional_Results_2024 |&gt;\n  mutate(Year = 2024)\n\nCombined_Minnesota_Congressional_Results &lt;- bind_rows(\n  Minnesota_Congressional_Results_2022,\n  Minnesota_Congressional_Results_2024)\n\n# Fix District Variable (To Match Geographic Data)\nCombined_Minnesota_Congressional_Results$District &lt;- sprintf(\"%02d\", Combined_Minnesota_Congressional_Results$District)\n\nCombined_Minnesota_Congressional_Results\n\n# A tibble: 32 × 4\n   District Party Voteshare  Year\n   &lt;chr&gt;    &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 01       R          53.8  2022\n 2 01       DFL        42.3  2022\n 3 02       R          45.6  2022\n 4 02       DFL        50.9  2022\n 5 03       R          40.4  2022\n 6 03       DFL        59.6  2022\n 7 04       R          32.3  2022\n 8 04       DFL        67.6  2022\n 9 05       R          24.5  2022\n10 05       DFL        74.3  2022\n# ℹ 22 more rows\n\n\n\nCode# Create the 'year_party' column for pivoting\nCombined_Minnesota_Congressional_Results &lt;- Combined_Minnesota_Congressional_Results |&gt;\n  mutate(year_party = paste0(tolower(Party), \"_\", Year))\n\n# Pivot The Data\nvoteshare_data &lt;- Combined_Minnesota_Congressional_Results |&gt;\n  pivot_wider(id_cols = District,\n              names_from = year_party,\n              values_from = `Voteshare`)\n\n# View Data \nvoteshare_data\n\n# A tibble: 8 × 5\n  District r_2022 dfl_2022 dfl_2024 r_2024\n  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 01         53.8     42.3     41.4   58.5\n2 02         45.6     50.9     55.5   42.1\n3 03         40.4     59.6     58.4   41.4\n4 04         32.3     67.6     67.2   32.6\n5 05         24.5     74.3     74.4   24.6\n6 06         62.0     37.8     37.4   62.4\n7 07         67.0     27.6     29.4   70.4\n8 08         57.2     42.7     41.9   58.0\n\n\n\nCodemn_cd_with_results &lt;- left_join(mn_cd, voteshare_data, by = c(\"CD118FP\" = \"District\"))\n\n# View Merged Data\nmn_cd_with_results\n\nSimple feature collection with 8 features and 13 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -97.22904 ymin: 43.49952 xmax: -89.48923 ymax: 49.38436\nGeodetic CRS:  NAD83\n  STATEFP CD118FP      AFFGEOID GEOID                 NAMELSAD LSAD CDSESSN\n1      27      05 5001800US2705  2705 Congressional District 5   C2     118\n2      27      03 5001800US2703  2703 Congressional District 3   C2     118\n3      27      06 5001800US2706  2706 Congressional District 6   C2     118\n4      27      02 5001800US2702  2702 Congressional District 2   C2     118\n5      27      08 5001800US2708  2708 Congressional District 8   C2     118\n6      27      04 5001800US2704  2704 Congressional District 4   C2     118\n7      27      01 5001800US2701  2701 Congressional District 1   C2     118\n8      27      07 5001800US2707  2707 Congressional District 7   C2     118\n        ALAND      AWATER r_2022 dfl_2022 dfl_2024 r_2024\n1   338801630    16523525  24.53    74.33    74.37  24.56\n2  1212366766   126629346  40.37    59.56    58.43  41.45\n3  6434599477   338776646  61.97    37.79    37.42  62.45\n4  4474617907   212911547  45.65    50.87    55.53  42.08\n5 80910616387 15048680132  57.18    42.72    41.92  57.99\n6   785198132    79844458  32.26    67.59    67.25  32.58\n7 31696870236   561074371  53.83    42.31    41.41  58.51\n8 80391767022  2552744290  66.95    27.61    29.44  70.45\n                        geometry\n1 MULTIPOLYGON (((-93.4007 45...\n2 MULTIPOLYGON (((-93.76753 4...\n3 MULTIPOLYGON (((-94.50614 4...\n4 MULTIPOLYGON (((-94.02525 4...\n5 MULTIPOLYGON (((-96.06762 4...\n6 MULTIPOLYGON (((-93.2277 45...\n7 MULTIPOLYGON (((-96.45332 4...\n8 MULTIPOLYGON (((-97.22904 4...\n\n\n\nCode# Create Color Palette for 2022 \npal_2022 &lt;- colorNumeric(palette = c(\"red\", \"blue\"), domain = mn_cd_with_results$democratic_2022)\n\n# Map for 2022 Election Results\nleaflet(mn_cd_with_results) |&gt; \n  addTiles() |&gt; \n  addPolygons(\n    fillColor = ~pal_2022(dfl_2022),  # Function needs to be called on the variable\n    fillOpacity = 1,\n    color = \"black\",\n    weight = 1) |&gt; \n  addLegend(\n    pal = pal_2022,\n    values = ~dfl_2022,\n    title = \"Democratic Voteshare (2022)\",\n    position = \"bottomright\")\n\n\n\n\n\n\nCode# Create Color Palette for 2024\npal_2024 &lt;- colorNumeric(palette = c(\"red\", \"blue\"), domain = mn_cd_with_results$democratic_2022)\n\n# Map for 2024 Election Results\nleaflet(mn_cd_with_results) |&gt; \n  addTiles() |&gt; \n  addPolygons(\n    fillColor = ~pal_2024(dfl_2024),\n    fillOpacity = 1,\n    color = \"black\",\n    weight = 1) |&gt; \n  addLegend(\n    pal = pal_2024,\n    values = ~dfl_2024,\n    title = \"Democratic Voteshare (2024)\",\n    position = \"bottomright\")\n\n\n\n\n\n\nCode# Calculate the Change in Voteshare (Between 2022 and 2024)\nmn_cd_with_results_1 &lt;- mn_cd_with_results |&gt;\n  mutate(\n    democratic_change = dfl_2024 - dfl_2022,\n    republican_change = r_2024 - r_2022)\n\nmn_cd_with_results_1\n\nSimple feature collection with 8 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -97.22904 ymin: 43.49952 xmax: -89.48923 ymax: 49.38436\nGeodetic CRS:  NAD83\n  STATEFP CD118FP      AFFGEOID GEOID                 NAMELSAD LSAD CDSESSN\n1      27      05 5001800US2705  2705 Congressional District 5   C2     118\n2      27      03 5001800US2703  2703 Congressional District 3   C2     118\n3      27      06 5001800US2706  2706 Congressional District 6   C2     118\n4      27      02 5001800US2702  2702 Congressional District 2   C2     118\n5      27      08 5001800US2708  2708 Congressional District 8   C2     118\n6      27      04 5001800US2704  2704 Congressional District 4   C2     118\n7      27      01 5001800US2701  2701 Congressional District 1   C2     118\n8      27      07 5001800US2707  2707 Congressional District 7   C2     118\n        ALAND      AWATER r_2022 dfl_2022 dfl_2024 r_2024\n1   338801630    16523525  24.53    74.33    74.37  24.56\n2  1212366766   126629346  40.37    59.56    58.43  41.45\n3  6434599477   338776646  61.97    37.79    37.42  62.45\n4  4474617907   212911547  45.65    50.87    55.53  42.08\n5 80910616387 15048680132  57.18    42.72    41.92  57.99\n6   785198132    79844458  32.26    67.59    67.25  32.58\n7 31696870236   561074371  53.83    42.31    41.41  58.51\n8 80391767022  2552744290  66.95    27.61    29.44  70.45\n                        geometry democratic_change republican_change\n1 MULTIPOLYGON (((-93.4007 45...              0.04              0.03\n2 MULTIPOLYGON (((-93.76753 4...             -1.13              1.08\n3 MULTIPOLYGON (((-94.50614 4...             -0.37              0.48\n4 MULTIPOLYGON (((-94.02525 4...              4.66             -3.57\n5 MULTIPOLYGON (((-96.06762 4...             -0.80              0.81\n6 MULTIPOLYGON (((-93.2277 45...             -0.34              0.32\n7 MULTIPOLYGON (((-96.45332 4...             -0.90              4.68\n8 MULTIPOLYGON (((-97.22904 4...              1.83              3.50\n\n\n\nCode# Map for Democratic Voteshare change\nplot_dem_change &lt;- ggplot(mn_cd_with_results_1) +\n  geom_sf(aes(fill = democratic_change), color = \"black\") +\n  scale_fill_gradient2(\n    low = \"red\",\n    mid = \"white\",\n    high = \"blue\",\n    midpoint = 0,\n    name = \"Dem. Change\\n(2022 - 2024)\") +\n  labs(\n    title = \"Change in Democratic Voteshare (2022 to 2024)\",\n    caption = \"Source: Minnesota Secretary of States Office (2023 and 2025)\") +\n  theme_minimal() + \n  theme(axis.text.x = element_blank(),\n        axis.text.y = element_blank())\n\nplot_dem_change\n\n\n\n\n\n9 Reflection:\nThe map offers several insightful observations about the shifts in Democratic voteshare between the 2022 midterm elections and the 2024 elections. Notably, Minnesota’s 2nd Congressional District experienced a significant shift in favor of Democratic candidate Angie Craig. This district has long been considered a swing district, but in 2024, Craig secured a commanding victory, greatly surpassing her 2022 performance and outperforming other Democrats in the state. Additionally, while Minnesota’s 7th District remains a heavily Republican area, it did shift slightly to the left. Most other districts showed moderate shifts to the right, consistent with national trends. Interestingly, Minnesota’s 5th District, the most Democratic in the state, showed no change between the two election cycles.\nThese shifts provide valuable insights into where Democratic candidates gained or lost support in 2024 and open the door to several important research questions. What campaign strategies, narratives, or tactics did certain candidates employ that may have contributed to their increased support? What role did money play in the outcome? These are all compelling questions that warrant further exploration by political scientists and data scientists alike."
  },
  {
    "objectID": "ica/ica-uni.html",
    "href": "ica/ica-uni.html",
    "title": "\n9  Univariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the univariate viz in-class activity. Refer to the class website for details.\n\n# Exercise 1\n# Import data \nhikes &lt;- read.csv(\"https://mac-stat.github.io/data/high_peaks.csv\")\nhead(hikes)\n\n             peak elevation difficulty ascent length time    rating\n1     Mt. Marcy        5344          5   3166   14.8 10.0  moderate\n2 Algonquin Peak       5114          5   2936    9.6  9.0  moderate\n3   Mt. Haystack       4960          7   3570   17.8 12.0 difficult\n4   Mt. Skylight       4926          7   4265   17.9 15.0 difficult\n5 Whiteface Mtn.       4867          4   2535   10.4  8.5      easy\n6       Dix Mtn.       4857          5   2800   13.2 10.0  moderate\n\n\nA. What features would we like a visualization of the categorical difficulty rating variable to capture? We may want a histogram to help us understand the relative difficulty of each of the hikes and understand relationships between difficulty and other variables.\nB. What about a visualization of the quantitative elevation variable? We would want to see clearly which mountains have higher elevation, and how that variable corresponds to the others, such as difficulty, ascent, etc.\n\n# Use the ggplot function\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nggplot(hikes, aes(x = rating))\n\n\n\n\nHow many hikes fall into each category? 1 easy, 3 are maderate, and 4 are difficult\nAre the hikes evenly distributed among these categories, or are some more common than others? Some are more common than others. They all have different frequencies.\nWhat did this do? What do you observe? It created an empty bar graph that categorizes the hikes as difficult, easy, or moderate along the x axis, and the frequency of the hikes in the dataset along the y axis.\nWhat, in general, is the first argument of the ggplot() function? Hikes\nWhat is the purpose of writing x = rating? It clearly communicates what the different categories on the x axis represent.\nWhat do you think aes stands for?!? aesthetic\n\n# COMMENT on the change in the code and the corresponding change in the plot --- It added bars in gray that visually represents the frequency of each of the categories in the data set of hikes. \nggplot(hikes, aes(x = rating)) +\n  geom_bar()\n\n\n\n\n\n# COMMENT on the change in the code and the corresponding change in the plot -- this adds clear labels to the y axis that make the visualization better and easier to understand \nggplot(hikes, aes(x = rating)) +\n  geom_bar() +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n# COMMENT on the change in the code and the corresponding change in the plot --- This changed the color of the bars to blue \nggplot(hikes, aes(x = rating)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n# COMMENT on the change in the code and the corresponding change in the plot --- this code gave the bars an orange outline (Go Scots!)\nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\") +\n  labs(x = \"Rating\", y = \"Number of hikes\")\n\n\n\n\n\n# COMMENT on the change in the code and the corresponding change in the plot --- this code made the background clearer. \nggplot(hikes, aes(x = rating)) +\n  geom_bar(color = \"orange\", fill = \"blue\")  +\n  labs(x = \"Rating\", y = \"Number of hikes\") +\n  theme_minimal()\n\n\n\n\n\n9.0.1 Part A: Questions\nReflect on the ggplot() code: The code ultimately generated a compelling and clear data visualization. The clear labeling and engaging coloring make this a great visual representation of the frequency and difficulty rating of the hikes in the data set.\nWhat’s the purpose of the +? When do we use it? The + is used to add layers, aesthetics, and other components to a ggplot object. It helps build plots step by step by connecting different commands.\nWe added the bars using geom_bar()? Why “geom”? The “geom” function creates the clear geometric bars for the graph.\nWhat does labs() stand for? It stands for “labels.”\nWhat’s the difference between color and fill? “Color” is the outline/trimming of the bars in the graph, and “fill” is the color that fills the geometric shape.\n\n9.0.2 Part B: Questions\nObserved categories: What categories did we observe? We can see three categories, namely “Easy”, “Moderate”, and “Difficult”\nVariability between categories: Are observations evenly spread out among the categories, or are some categories more common than others? No they are not evenly spread out. There are more “moderate” hikes represented in the dataset.\nSummarize below what you learned from the bar chart, in context. We learned that there is a significantly higher number of “moderate” hikes in the Adirondacks, compared to less “easy” hikes and even fewere “difficult” hikes. Most of the terrain falls outsides of the extremes of difficulty (easy, difficult).\n\n9.0.3 Part C: Questions\nIs there anything you don’t like about this barplot? I would prefer that the order of the categories be more clear. I’d order it (easy, then moderate, and difficult) This would better capture that the most of the hikes fall in the middle of the x-axis, which represents the level of difficulty."
  },
  {
    "objectID": "ica/ica-bi.html",
    "href": "ica/ica-bi.html",
    "title": "\n10  Bivariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the bivariate viz in-class activity. Refer to the class website for details.\n\n# Load data\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n# Check it out\nhead(elections)\n\n  state_name state_abbr historical    county_name county_fips total_votes_20\n1    Alabama         AL        red Autauga County        1001          27770\n2    Alabama         AL        red Baldwin County        1003         109679\n3    Alabama         AL        red Barbour County        1005          10518\n4    Alabama         AL        red    Bibb County        1007           9595\n5    Alabama         AL        red  Blount County        1009          27588\n6    Alabama         AL        red Bullock County        1011           4613\n  repub_pct_20 dem_pct_20 winner_20 total_votes_16 repub_pct_16 dem_pct_16\n1        71.44      27.02     repub          24661        73.44      23.96\n2        76.17      22.41     repub          94090        77.35      19.57\n3        53.45      45.79     repub          10390        52.27      46.66\n4        78.43      20.70     repub           8748        76.97      21.42\n5        89.57       9.57     repub          25384        89.85       8.47\n6        24.84      74.70       dem           4701        24.23      75.09\n  winner_16 total_votes_12 repub_pct_12 dem_pct_12 winner_12 total_population\n1     repub          23909        72.63      26.58     repub            54907\n2     repub          84988        77.39      21.57     repub           187114\n3     repub          11459        48.34      51.25       dem            27321\n4     repub           8391        73.07      26.22     repub            22754\n5     repub          23980        86.49      12.35     repub            57623\n6       dem           5318        23.51      76.31       dem            10746\n  percent_white percent_black percent_asian percent_hispanic per_capita_income\n1            76            18             1                2             24571\n2            83             9             1                4             26766\n3            46            46             0                5             16829\n4            75            22             0                2             17427\n5            88             1             0                8             20730\n6            22            71             0                6             18628\n  median_rent median_age\n1         668       37.5\n2         693       41.5\n3         382       38.3\n4         351       39.4\n5         403       39.6\n6         276       39.6\n\n\nPart A: I guess that the Republican candidate won 73% of counties.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nggplot(elections, aes(x = winner_20)) + geom_bar()\n\n\n\n\n\nggplot(elections, aes(x=repub_pct_20)) + \n  geom_histogram(color = \"white\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nggplot(elections, aes(x = repub_pct_20)) + \n  geom_density()\n\n\n\n\n\n# Set up the plotting fram \n# How does this differn than the fram for our histogram of repub_pct_20 alone?\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16))\n\n\n\n\n\n# Add a layer of points for each ocunty \n# Take note of the geom! \nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) + \n  geom_point()\n\n\n\n\n\n#Change the shape of the points \n#What happens if you change the shape to another number \nggplot(elections, aes(y=repub_pct_20, x = repub_pct_16)) + \n  geom_point(shape = 3,  color = \"blue\") + geom_text(aes(label = state_abbr)) +  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe relationship between the two variables is positive and linear. This data visualization tells me that for the most part, counties across the U.S. voted similarly in 2016 and 2020. There are a few notable outliers, espcially several counties in Texas.\n\nggplot(elections, aes(y = repub_pct_20, x = repub_pct_16)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n#Scatterplot of repub_pct_20 vs. median_rent \nggplot(elections, aes(y = repub_pct_20, x = median_rent)) + geom_point() + geom_smooth(method = \"lm\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Scatterplot of repub_pct_20 vs median_age\nggplot(elections, aes(y = repub_pct_20, x = median_age)) +\n  geom_point() + geom_smooth(method = \"lm\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n# Violin plots\nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_violin()\n\n\n\n\n\n# Boxplots \nggplot(elections, aes(y = repub_pct_20, x = historical)) +\n  geom_boxplot()\n\n\n\n\n\n# The colors used don't match up with the blue, purple, red labels\n# The density plots are on top of each other\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density()\n\n\n\n\n\n# scale_fill_manual \"hard codes\" or defines what colors to use for the fill categories\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n# alpha = 0.5 adds transparency\n# the closer alpha is to 0, the more transparent.\n# the closer alpha is to 1, the more opaque.\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n\n\n\n\n# facet_wrap separates the density plots into \"facets\" for each historical group\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_density() +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\")) +\n  facet_wrap(~ historical)\n\n\n\n\n\n# Let's try a similar grouping strategy with a histogram instead of density plot.\n# Why is this terrible?\nggplot(elections, aes(x = repub_pct_20, fill = historical)) +\n  geom_histogram(color = \"white\") +\n  scale_fill_manual(values = c(\"blue\", \"purple\", \"red\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nOne pro of density plots relative to boxplots: doesn’t oversimplify the data / boil the data down to just 5 numbers.\nName one con of density plots relative to boxplots: boxplots can be easier to interpret\n\n# A stacked bar plot\n# historical = x axis / bar categories\n# winner_20 = fills the bars\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar()\n\n\n\n\n\n# A faceted bar plot\nggplot(elections, aes(x = winner_20)) +\n  geom_bar() +\n  facet_wrap(~ historical)\n\n\n\n\n\n# A side-by-side bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n# A proportional bar plot\n# Note the new argument to geom_bar\nggplot(elections, aes(x = historical, fill = winner_20)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\nweather &lt;- read.csv(\"https://mac-stat.github.io/data/weather_3_locations.csv\")\n\n# How do 3pm temperatures (temp3pm) differ by location?\nggplot(weather, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5)\n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\nggplot(weather, aes(y = temp3pm, x = location)) + \n  geom_boxplot()\n\nWarning: Removed 19 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n# How might we predict the 3pm temperature (temp3pm) by the 9am temperature (temp9am)?\nggplot(weather, aes(y = temp3pm, x = temp9am)) + \n  geom_point()\n\nWarning: Removed 27 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n# How do the number of rainy days (raintoday) differ by location?\nggplot(weather, aes(x = location, fill = raintoday)) + \n  geom_bar()"
  },
  {
    "objectID": "ica/ica-multi.html",
    "href": "ica/ica-multi.html",
    "title": "\n11  ICA Mulivariate Viz\n",
    "section": "",
    "text": "Use this file for practice with the mulivariate viz in-class activity. Refer to the class website for details.\n\n#Download GGPLOT\nlibrary(ggplot2) \n\n# Import Education Data\neducation &lt;- read.csv(\"https://mac-stat.github.io/data/sat.csv\")\nhead(education)\n\n       State expend ratio salary frac verbal math  sat  fracCat\n1    Alabama  4.405  17.2 31.144    8    491  538 1029   (0,15]\n2     Alaska  8.963  17.6 47.951   47    445  489  934 (45,100]\n3    Arizona  4.778  19.3 32.175   27    448  496  944  (15,45]\n4   Arkansas  4.459  17.1 28.934    6    482  523 1005   (0,15]\n5 California  4.992  24.0 41.078   45    417  485  902  (15,45]\n6   Colorado  5.443  18.4 34.571   29    462  518  980  (15,45]\n\n\n\n# Part A: Create histogram\nggplot(education, aes(x = sat)) + \n  geom_density()\n\n\n\n\nPart B: The average scores are between 800 to 1100. They are bi-modal\n\n# SAT Scores vs Per Pupil Spending\nggplot(education, aes(y = sat, x = expend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n# Plot of SAT Scores vs. Salary\nggplot(education, aes(y = sat, x = salary)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\nPart B: The plot shows that typically, the higher per student spending and teacher salaries, the worse the SAT scores.\n\n# Create plot for SAT Scores vs. Per Student Spending Vs. Teacher Salaries \nggplot(education, aes(y = sat, x = salary, color = expend)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n# Exercise 4\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 2))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\nggplot(education, aes(y = sat, x = salary, color = cut(expend, 3))) + \n  geom_point() + \n  geom_smooth(se = FALSE, method = \"lm\")\n\n\n\n\n\n#Exercise 5, Part A\nggplot(education, aes(x = fracCat)) + \n  geom_bar()\n\n\n\n\n\n#Part B\nggplot(education, aes(x = sat, fill = fracCat)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\n#Part c\nggplot(education, aes(y = sat, x = expend, color = fracCat)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n\n\n\n\n#Exercise 6: Let's Make Some Heat Maps\n\nlibrary(tibble)\n\n#Part A\n# Remove the \"State\" column and use it to label the rows\n# Then scale the variables\nplot_data &lt;- education |&gt; \n  column_to_rownames(\"State\") |&gt; \n  data.matrix() |&gt; \n  scale()\n\n\n#Exercise 7: Create Star Plots\n\n#Part A\nstars(plot_data,\n  flip.labels = FALSE,\n  key.loc = c(10, 1.5),\n  cex = 1, \n  draw.segments = TRUE)\n\n\n\n\n\n#Part B\nstars(plot_data,\n  flip.labels = FALSE,\n  locations = data.matrix(as.data.frame(state.center)),  # added external data to arrange by geo location\n  key.loc = c(-110, 28),\n  cex = 1, \n  draw.segments = TRUE)"
  },
  {
    "objectID": "ica/ica-spatial.html",
    "href": "ica/ica-spatial.html",
    "title": "\n12  Exercise 1: A Leaflet With Markers / Points ###\n",
    "section": "",
    "text": "Use this file for practice with the spatial viz in-class activity. Refer to the class website for details.\n\n\nfave_places &lt;- read.csv(\"https://hash-mac.github.io/stat112site-s25/data/our_fave_places.csv\")\n\n# Check it out\nhead(fave_places)\n\n  latitude longitude\n1       59        18\n2       45       -93\n3       33      -117\n4       40       116\n5       40       106\n6       37      -122\n\n\n\n### Part A ###\n\n# Load Leaflet\nlibrary(leaflet)\n\n# Just a plotting frame\nleaflet(data = fave_places)\n\n\n\n\n\n\n# Now what do we have?\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addMarkers(lng = ~longitude, lat = ~latitude)\n\n\n\n\n\n\n### Exercise 2: Details ###\n\n# Load package needed to change color\nlibrary(gplots)\n\n# We can add colored circles instead of markers at each location\nleaflet(data = fave_places) |&gt; \n  addTiles() |&gt; \n  addCircles(color = col2hex(\"red\"))\n\n\n\n\n\n\nleaflet(data = fave_places) |&gt;\n  addProviderTiles(\"USGS\") |&gt; # Change the background \n  addCircles(weight = 10, opacity = 1, color = col2hex(\"yellow\")) |&gt; #Mark locations with yellow dots\n  addPolylines(\n    lng = ~longitude,\n    lat = ~latitude,\n    color = col2hex(\"green\")) # Connect the dots with green lines\n\n\n\n\n\n\n### Exercise 3 ###\n\n#Load Libraries\nlibrary(dplyr)\nlibrary(leaflet)\nlibrary(ggplot2)\n\n# Import starbucks location data\nstarbucks &lt;- read.csv(\"https://mac-stat.github.io/data/starbucks.csv\")\n\n# Filter for Starbucks in Minnesota\nstarbucks_mn &lt;- starbucks |&gt;   \n  filter(Country == \"US\", State.Province == \"MN\")\n\n#Create Leaflet\nleaflet(data = starbucks_mn) |&gt; \n  addTiles() |&gt; \n  addMarkers()\n\n\n\n\n\n\n### Exercise 4 ###\n\n#Part A: First, we can grab country-level boundaries from the rnaturalearth package.\n\n# Load the rnaturalearth package\nlibrary(rnaturalearth)\n\n# Retrieve world country boundaries in \"sf\" (simple features) format\nworld_boundaries &lt;- ne_countries(returnclass = \"sf\")\n\n\n#Part B\n# This code produces a world map showing country boundaries.\n# What geom are we using for the point map? We are using geom_sf() to create the geometric shapes \nggplot(world_boundaries) + \n  geom_sf()\n\n\n\n\n\n# Load package needed to change map theme\nlibrary(mosaic)\n\n# Add a point for each Starbucks\n# NOTE: The Starbucks info is in our starbucks data, not world_boundaries\n# How does this change how we use geom_point?!\nggplot(world_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3, size = 0.2, color = \"darkgreen\") +\n  theme_map()\n\n\n\n\nPart C: The map visually highlights that Starbucks has a strong presence in North America, Europe, and East Asia, a moderate presence in some other regions, and a very limited footprint in Africa.\n\n### Exercise 5: Zooming in on some countries ###\n\n#Part A\nstarbucks_cma &lt;- starbucks |&gt; \n  filter(Country %in% c('CA', 'MX', 'US'))\n\n#A Background Map of State\ncma_boundaries &lt;- ne_states(\n  country = c(\"canada\", \"mexico\", \"united states of america\"),\n  returnclass = \"sf\")\n\n\n#Part B\n# Just the boundaries\nggplot(cma_boundaries) + \n  geom_sf()\n\n\n\n\n\n# Add the points\n# And zoom in\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50)) +\n  theme_map()\n\n\n\n\n\n# Exercise 6: Create a state and county-level map\n\n#Part A\nstarbucks_midwest &lt;- starbucks |&gt; \n  filter(State.Province %in% c(\"MN\", \"ND\", \"SD\", \"WI\"))\n\n# Load packages\nlibrary(sf)\nlibrary(maps)\n\n# Get the boundaries\nmidwest_boundaries &lt;- st_as_sf(\n  maps::map(\"county\",\n            region = c(\"minnesota\", \"wisconsin\", \"north dakota\", \"south dakota\"), \n            fill = TRUE, plot = FALSE))\n\n# Check it out\nhead(midwest_boundaries)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -96.81268 ymin: 45.05167 xmax: -93.01397 ymax: 48.53526\nGeodetic CRS:  +proj=longlat +ellps=clrk66 +no_defs +type=crs\n                                     ID                           geom\nminnesota,aitkin       minnesota,aitkin MULTIPOLYGON (((-93.03689 4...\nminnesota,anoka         minnesota,anoka MULTIPOLYGON (((-93.51817 4...\nminnesota,becker       minnesota,becker MULTIPOLYGON (((-95.14537 4...\nminnesota,beltrami   minnesota,beltrami MULTIPOLYGON (((-95.58655 4...\nminnesota,benton       minnesota,benton MULTIPOLYGON (((-93.77027 4...\nminnesota,big stone minnesota,big stone MULTIPOLYGON (((-96.10794 4...\n\n\n\n# Part B\nggplot(midwest_boundaries) +\n  geom_sf() +\n  geom_point(\n    data = starbucks_midwest,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.7,\n    size = 0.2,\n    color = 'darkgreen') +\n  theme_map()\n\n\n\n\n\n### Exercise 7: Contour Maps ###\n\n# Point map (we made this earlier)\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_point(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    alpha = 0.3,\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n# What changed in the plot?\n# What changed in our code?!\nggplot(cma_boundaries) + \n  geom_sf() + \n  geom_density_2d(\n    data = starbucks_cma,\n    aes(x = Longitude, y = Latitude),\n    size = 0.2,\n    color = \"darkgreen\"\n  ) +\n  coord_sf(xlim = c(-179.14, -50), ylim = c(14.54, 83.11)) +\n  theme_map()\n\n\n\n\n\n### PART 3: Choropleth Maps ### \nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n#CODE\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\nExercise 8: State-level choropleth maps\n\n#Part A\n\n# Get the latitude and longitude coordinates of state boundaries\nstates_map &lt;- map_data(\"state\")\n\n# Check it out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\n\n# Part B\n# Note where the dataset, elections_by_state, is used\n# Note where the background map, states_map, is used\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() \n\n\n\n\n\n# Make it nicer!\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_pct_20)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_gradientn(name = \"% Republican\", colors = c(\"blue\", \"purple\", \"red\"), values = scales::rescale(seq(0, 100, by = 5)))\n\n\n\n\n\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map()\n\n\n\n\n\n# Load package needed for refining color palette\nlibrary(RColorBrewer)\n\n# Now fix the colors\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\n\n#Part C\n# Get only the starbucks data from the US\nstarbucks_us &lt;- starbucks |&gt; \n  filter(Country == \"US\")\n\n# Map it\nggplot(elections_by_state, aes(map_id = state_name, fill = repub_20_categories)) +\n  geom_map(map = states_map) +\n  geom_point(\n    data = starbucks_us,\n    aes(x = Longitude, y = Latitude),\n    size = 0.05,\n    alpha = 0.2,\n    inherit.aes = FALSE\n  ) +\n  expand_limits(x = states_map$long, y = states_map$lat) +\n  theme_map() + \n  scale_fill_manual(values = rev(brewer.pal(8, \"RdBu\")), name = \"% Republican\")\n\n\n\n\nExercise 9: County-level choropleth maps\n\n#Part A\n# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\n\n# Add 0's at the beginning of any fips_code that's fewer than 5 numbers long\n# Don't worry about the syntax\nelections_by_counties &lt;- elections_by_counties |&gt; \n  mutate(county_fips = as.character(county_fips)) |&gt; \n  mutate(county_fips = \n           ifelse(nchar(county_fips) == 4, paste0(\"0\", county_fips), county_fips))\n\n\n#Part B\nggplot(elections_by_counties, aes(map_id = county_fips, fill = repub_20_categories)) +\n  geom_map(map = county_map) +\n  scale_fill_manual(values = rev(brewer.pal(10, \"RdBu\")), name = \"% Republican\") +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal()\n\n\n\n\n\n12.0.1 Spacial Vizualization: Exercise #10\nConstruct county-level maps of median_rent and median_age.\n\n# Download Datasets\nelections_by_state &lt;-  read.csv(\"https://mac-stat.github.io/data/election_2020_by_state.csv\")\nelections_by_counties &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n# Wrangle the Data\nelections_by_state &lt;- elections_by_state |&gt; \n  filter(state_abbr != \"DC\") |&gt; \n  select(state_name, state_abbr, repub_pct_20) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(30, 70, by = 5), \n               labels = c(\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                          \"50-54\", \"55-59\", \"60-64\", \"65-70\"), \n               include.lowest = TRUE))\n\nelections_by_counties &lt;- elections_by_counties |&gt; \n  select(state_name, state_abbr, county_name, county_fips,\n          repub_pct_20, median_age, median_rent) |&gt; \n  mutate(repub_20_categories = \n           cut(repub_pct_20, \n               breaks = seq(0, 100, by = 10),\n               labels = c(\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\",\n                          \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-100\"),\n               include.lowest = TRUE))\n\n\n# Get Latitude and Longitude Coordinates of States\nstates_map &lt;- map_data(\"state\")\n\n# Check It Out\nhead(states_map)\n\n       long      lat group order  region subregion\n1 -87.46201 30.38968     1     1 alabama      &lt;NA&gt;\n2 -87.48493 30.37249     1     2 alabama      &lt;NA&gt;\n3 -87.52503 30.37249     1     3 alabama      &lt;NA&gt;\n4 -87.53076 30.33239     1     4 alabama      &lt;NA&gt;\n5 -87.57087 30.32665     1     5 alabama      &lt;NA&gt;\n6 -87.58806 30.32665     1     6 alabama      &lt;NA&gt;\n\n\n\n# Get the latitude and longitude coordinates of county boundaries\nlibrary(socviz)\ndata(county_map) \n\n# Check it out\nhead(county_map)\n\n     long      lat order  hole piece            group    id\n1 1225889 -1275020     1 FALSE     1 0500000US01001.1 01001\n2 1235324 -1274008     2 FALSE     1 0500000US01001.1 01001\n3 1244873 -1272331     3 FALSE     1 0500000US01001.1 01001\n4 1244129 -1267515     4 FALSE     1 0500000US01001.1 01001\n5 1272010 -1262889     5 FALSE     1 0500000US01001.1 01001\n6 1276797 -1295514     6 FALSE     1 0500000US01001.1 01001\n\n\n\n# Create A County-Level Map of median_rent \nggplot(elections_by_counties, aes(map_id = county_fips, fill = median_rent)) +\n  geom_map(map = county_map) +\n  expand_limits(x = county_map$long, y = county_map$lat) +\n  theme_map() +\n  theme(legend.position = \"right\") + \n  coord_equal() + \n  scale_fill_gradientn(name = \"median rent\", colors = c(\"white\", \"lightgreen\", \"darkgreen\"))"
  },
  {
    "objectID": "ica/ica-wrangling.html",
    "href": "ica/ica-wrangling.html",
    "title": "\n13  Wrangling\n",
    "section": "",
    "text": "14 Exercise 1: Select Practice\n\n# Load tidyverse & data\nlibrary(tidyverse)\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\")\n\n\n# Define elections_small\nelections_small &lt;- elections |&gt;\n  select(state_name, county_name, total_votes_20, repub_pct_20, dem_pct_20, total_votes_16, dem_pct_16)\n\n# Check out the first 6 rows to confirm your code did what you think it did!\nhead(elections_small)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16\n1          24661      23.96\n2          94090      19.57\n3          10390      46.66\n4           8748      21.42\n5          25384       8.47\n6           4701      75.09\n\n\n\n15 Exercise 2: Filter Demo\n\n# Keep only data on counties in Hawaii\nelections_small |&gt;\n filter(state_name == \"Hawaii\")\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1     Hawaii   Hawaii County          87814        30.63      66.88\n2     Hawaii Honolulu County         382114        35.66      62.51\n3     Hawaii    Kauai County          33497        34.58      63.36\n4     Hawaii     Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          64865      63.61\n2         285683      61.48\n3          26335      62.49\n4          51942      64.45\n\n\n\n# Keep counties in Hawaii AND Delaware\nelections_small |&gt; \n  filter(state_name %in% c(\"Hawaii\", \"Delaware\"))\n\n  state_name       county_name total_votes_20 repub_pct_20 dem_pct_20\n1   Delaware       Kent County          87025        47.12      51.19\n2   Delaware New Castle County         287633        30.72      67.81\n3   Delaware     Sussex County         129352        55.07      43.82\n4     Hawaii     Hawaii County          87814        30.63      66.88\n5     Hawaii   Honolulu County         382114        35.66      62.51\n6     Hawaii      Kauai County          33497        34.58      63.36\n7     Hawaii       Maui County          71044        31.14      66.59\n  total_votes_16 dem_pct_16\n1          74253      44.91\n2         261468      62.30\n3         105814      37.17\n4          64865      63.61\n5         285683      61.48\n6          26335      62.49\n7          51942      64.45\n\n\n\n# Keep only data on counties where the Republican got MORE THAN 93.97% of the vote in 2020\nelections_small |&gt; \n  filter(repub_pct_20 &gt; 93.97)\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  Borden County            416        95.43       3.85\n2      Texas    King County            159        94.97       5.03\n3      Texas Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            365       8.49\n2            159       3.14\n3            550       3.64\n\n\n\n# Keep only data on counties where the Republican got AT LEAST 93.97% of the vote in 2020\n# This should have 1 more row than your answer above\nelections_small |&gt; \n  filter(repub_pct_20 &gt;= 93.97)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Montana Garfield County            813        93.97       5.04\n2      Texas   Borden County            416        95.43       3.85\n3      Texas     King County            159        94.97       5.03\n4      Texas  Roberts County            550        96.18       3.09\n  total_votes_16 dem_pct_16\n1            715       4.76\n2            365       8.49\n3            159       3.14\n4            550       3.64\n\n\n\n# Keep only data on counties in Texas where the Democrat got more than 65% of the vote in 2020\n# Do this 2 ways.\n# Method 1: 2 filters with 1 condition each\nelections_small |&gt;\n filter(state_name == \"Texas\") |&gt;\n filter(dem_pct_20 &gt; 65)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\n\n\n# Method 2: 1 filter with 2 conditions\nelections_small |&gt;\n filter(state_name == \"Texas\", dem_pct_20 &gt; 65)\n\n  state_name     county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas  El Paso County         267215        31.56      66.66\n2      Texas Presidio County           2217        32.52      65.99\n3      Texas   Travis County         610349        26.43      71.41\n4      Texas   Zavala County           4379        34.03      65.40\n  total_votes_16 dem_pct_16\n1         210458      69.14\n2           2203      66.18\n3         462511      66.26\n4           3390      77.67\n\n\n\n16 Exercise 3: Arrange Demo\n\n# Arrange the counties in elections_small from lowest to highest percentage of 2020 Republican support\n# Print out just the first 6 rows\nelections_small |&gt;\n  arrange(repub_pct_20) |&gt;\n  head()\n\n            state_name            county_name total_votes_20 repub_pct_20\n1 District of Columbia   District of Columbia         344356         5.40\n2             Maryland Prince George's County         424855         8.73\n3             Maryland         Baltimore city         237461        10.69\n4             Virginia        Petersburg city          14118        11.22\n5             New York        New York County         694904        12.26\n6           California   San Francisco County         443458        12.72\n  dem_pct_20 total_votes_16 dem_pct_16\n1      92.15         280272      92.85\n2      89.26         351091      89.33\n3      87.28         208980      85.44\n4      87.75          13717      87.52\n5      86.78         591368      87.17\n6      85.27         365295      85.53\n\n\n\n# Arrange the counties in elections_small from highest to lowest percentage of 2020 Republican support\n# Print out just the first 6 rows\nelections_small |&gt;\n  arrange(desc(repub_pct_20)) |&gt;\n  head()\n\n  state_name      county_name total_votes_20 repub_pct_20 dem_pct_20\n1      Texas   Roberts County            550        96.18       3.09\n2      Texas    Borden County            416        95.43       3.85\n3      Texas      King County            159        94.97       5.03\n4    Montana  Garfield County            813        93.97       5.04\n5      Texas Glasscock County            653        93.57       5.97\n6   Nebraska     Grant County            402        93.28       4.98\n  total_votes_16 dem_pct_16\n1            550       3.64\n2            365       8.49\n3            159       3.14\n4            715       4.76\n5            602       5.65\n6            394       5.08\n\n\n\n17 Exercise 4: Mutate Demo\n\n# Define diff_20, the difference btwn the Repub and Dem percent in 2020\nelections_small |&gt; \n  mutate(diff_20 = repub_pct_20 - dem_pct_20) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 diff_20\n1          24661      23.96   44.42\n2          94090      19.57   53.76\n3          10390      46.66    7.66\n4           8748      21.42   57.73\n5          25384       8.47   80.00\n6           4701      75.09  -49.86\n\n\n\n# Define repub_votes_20, the number (not percent) of Repub votes in 2020\nelections_small |&gt; \n  mutate(repub_votes_20 = round(total_votes_20 * repub_pct_20/100)) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_votes_20\n1          24661      23.96          19839\n2          94090      19.57          83542\n3          10390      46.66           5622\n4           8748      21.42           7525\n5          25384       8.47          24711\n6           4701      75.09           1146\n\n\n\n# Define repub_win_20, whether the Repub won in 2020 (TRUE or FALSE!)\nelections_small |&gt; \n  mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_win_20\n1          24661      23.96         TRUE\n2          94090      19.57         TRUE\n3          10390      46.66         TRUE\n4           8748      21.42         TRUE\n5          25384       8.47         TRUE\n6           4701      75.09        FALSE\n\n\n\n# Define repub_votes_20, the number (not percent) of Repub votes in 2020\nelections_small |&gt; \n  mutate(repub_votes_20 = round(total_votes_20 * repub_pct_20/100)) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_votes_20\n1          24661      23.96          19839\n2          94090      19.57          83542\n3          10390      46.66           5622\n4           8748      21.42           7525\n5          25384       8.47          24711\n6           4701      75.09           1146\n\n\n\n# Define repub_win_20, whether the Repub won in 2020 (TRUE or FALSE!)\nelections_small |&gt; \n  mutate(repub_win_20 = repub_pct_20 &gt; dem_pct_20) |&gt; \n  head()\n\n  state_name    county_name total_votes_20 repub_pct_20 dem_pct_20\n1    Alabama Autauga County          27770        71.44      27.02\n2    Alabama Baldwin County         109679        76.17      22.41\n3    Alabama Barbour County          10518        53.45      45.79\n4    Alabama    Bibb County           9595        78.43      20.70\n5    Alabama  Blount County          27588        89.57       9.57\n6    Alabama Bullock County           4613        24.84      74.70\n  total_votes_16 dem_pct_16 repub_win_20\n1          24661      23.96         TRUE\n2          94090      19.57         TRUE\n3          10390      46.66         TRUE\n4           8748      21.42         TRUE\n5          25384       8.47         TRUE\n6           4701      75.09        FALSE\n\n\n#Exercise 5: Pipe Series\nPart c It’s more “computationally efficient” to get rid of some rows before arranging.\nPart e We can’t select a variable before we define it!\n#Exercise 6: DIY Pipe Series\nPart A\n\n# Remember to try this 1 line at a time\nelections_small |&gt; \n  filter(state_name == \"Minnesota\") |&gt; \n  select(county_name, dem_pct_20) |&gt; \n  arrange(desc(dem_pct_20))\n\n                county_name dem_pct_20\n1             Ramsey County      71.50\n2           Hennepin County      70.46\n3               Cook County      65.58\n4          St. Louis County      56.64\n5             Dakota County      55.73\n6            Olmsted County      54.16\n7         Washington County      53.46\n8         Blue Earth County      50.84\n9               Clay County      50.74\n10              Lake County      50.64\n11          Nicollet County      50.31\n12           Carlton County      49.58\n13            Winona County      49.07\n14              Rice County      48.76\n15          Mahnomen County      48.26\n16             Anoka County      47.79\n17          Beltrami County      47.24\n18            Carver County      46.37\n19             Mower County      46.00\n20             Scott County      45.52\n21           Houston County      42.42\n22           Goodhue County      41.23\n23          Freeborn County      40.96\n24            Norman County      40.80\n25            Itasca County      40.61\n26       Koochiching County      38.41\n27          Watonwan County      38.20\n28           Kittson County      38.12\n29           Stevens County      37.80\n30           Stearns County      37.58\n31          Fillmore County      37.48\n32            Steele County      37.47\n33         Kandiyohi County      36.12\n34            Aitkin County      35.98\n35              Lyon County      35.94\n36     Lac qui Parle County      35.79\n37           Wabasha County      35.78\n38             Grant County      35.58\n39          Traverse County      35.46\n40         Big Stone County      35.41\n41        Pennington County      35.29\n42              Pope County      35.27\n43              Polk County      34.88\n44              Cass County      34.68\n45            Wright County      34.49\n46           Hubbard County      34.42\n47             Swift County      34.35\n48         Crow Wing County      34.17\n49           Chisago County      34.15\n50            Becker County      33.96\n51              Pine County      33.87\n52          Le Sueur County      33.73\n53          Chippewa County      33.67\n54            Nobles County      33.65\n55            Waseca County      33.65\n56             Dodge County      33.47\n57        Otter Tail County      32.85\n58            Benton County      32.70\n59           Douglas County      32.56\n60             Brown County      32.48\n61         Sherburne County      32.48\n62         Faribault County      31.98\n63          Red Lake County      31.47\n64          Renville County      30.71\n65            McLeod County      30.64\n66   Yellow Medicine County      30.54\n67           Lincoln County      30.08\n68        Cottonwood County      30.03\n69           Kanabec County      30.02\n70            Martin County      30.02\n71           Jackson County      29.99\n72        Mille Lacs County      29.98\n73            Wilkin County      29.91\n74              Rock County      29.69\n75            Murray County      29.60\n76            Isanti County      29.45\n77            Sibley County      28.60\n78            Meeker County      28.58\n79           Redwood County      28.43\n80 Lake of the Woods County      27.87\n81        Clearwater County      26.76\n82         Pipestone County      26.44\n83            Wadena County      26.35\n84            Roseau County      25.98\n85          Marshall County      25.33\n86              Todd County      24.79\n87          Morrison County      22.33\n\n\nPart B\n\n# Remember to try this 1 line at a time before storing!\nmn_wi &lt;- elections_small |&gt; \n  filter(state_name %in% c(\"Minnesota\", \"Wisconsin\")) |&gt; \n  select(state_name, county_name, dem_pct_20, dem_pct_16) |&gt;\n  mutate(dem_change = dem_pct_20 - dem_pct_16) |&gt; \n  arrange(dem_change)\n  \n# Check it out\nhead(mn_wi)\n\n  state_name        county_name dem_pct_20 dem_pct_16 dem_change\n1  Minnesota     Stevens County      37.80      39.55      -1.75\n2  Wisconsin      Forest County      34.06      35.12      -1.06\n3  Wisconsin    Kewaunee County      32.87      33.73      -0.86\n4  Wisconsin       Clark County      30.37      31.19      -0.82\n5  Wisconsin       Adams County      36.63      37.40      -0.77\n6  Wisconsin Trempealeau County      40.86      41.57      -0.71\n\n\nPart C\n\nggplot(mn_wi, aes(x = dem_change, fill = state_name)) + \n  geom_density(alpha = 0.5)\n\n\n\n\n\nggplot(mn_wi, aes(y = dem_change, x = state_name)) + \n  geom_boxplot()\n\n\n\n\n\n18 Exercise 7: Summarize Demo\n\n# Calculate the median Repub vote percentage in 2020 across all counties\nelections_small |&gt; \n  summarize(median(repub_pct_20))\n\n  median(repub_pct_20)\n1                68.29\n\n\n\n# Calculate the median Repub vote percentage in 2020 across all counties\n# AND name it \"median_repub\"\nelections_small |&gt; \n  summarize(median_repub = median(repub_pct_20))\n\n  median_repub\n1        68.29\n\n\n\n# Calculate the median Repub vote percentage in 2020 across all counties\n# AND the total number of votes across all counties\n# AND name the results\nelections_small |&gt; \n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20))\n\n  median_repub total_votes\n1        68.29   157949293\n\n\n#Exercise 8: Summarize + Group_by Demo\n\n# Calculate the median 2020 Repub percent and total votes BY STATE\nelections_small |&gt; \n  group_by(state_name) |&gt; \n  summarize(median_repub = median(repub_pct_20), total_votes = sum(total_votes_20)) \n\n# A tibble: 50 × 3\n   state_name           median_repub total_votes\n   &lt;chr&gt;                       &lt;dbl&gt;       &lt;int&gt;\n 1 Alabama                      70.6     2323304\n 2 Arizona                      57.9     3387326\n 3 Arkansas                     72.1     1219069\n 4 California                   44.8    17495906\n 5 Colorado                     56.2     3256953\n 6 Connecticut                  41.0     1824280\n 7 Delaware                     47.1      504010\n 8 District of Columbia          5.4      344356\n 9 Florida                      64.6    11067456\n10 Georgia                      68       4997716\n# ℹ 40 more rows\n\n\n#Exercise 9: DIY\nPart A\n\n# Sort the states from the most to least total votes in 2020\nelections_small |&gt; \n  group_by(state_name) |&gt; \n  summarize(total = sum(total_votes_20)) |&gt; \n  arrange(desc(total))\n\n# A tibble: 50 × 2\n   state_name        total\n   &lt;chr&gt;             &lt;int&gt;\n 1 California     17495906\n 2 Texas          11317911\n 3 Florida        11067456\n 4 New York        8616205\n 5 Pennsylvania    6925255\n 6 Illinois        6038850\n 7 Ohio            5922202\n 8 Michigan        5539302\n 9 North Carolina  5524801\n10 Georgia         4997716\n# ℹ 40 more rows\n\n\n\n# In 2020, what were the total number of votes for the Democratic candidate and the total number of votes for the Republican candidate in each *state*?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20))\n\n# A tibble: 50 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Alabama                 849664     1441155\n 2 Arizona                1672127     1661671\n 3 Arkansas                423919      760641\n 4 California            11109642     6006031\n 5 Colorado               1804393     1364627\n 6 Connecticut            1080677      715315\n 7 Delaware                296274      200601\n 8 District of Columbia    317324       18595\n 9 Florida                5297131     5668600\n10 Georgia                2473661     2461869\n# ℹ 40 more rows\n\n\n\n# What states did the Democratic candidate win in 2020?\nelections_small |&gt; \n  mutate(dem_votes_20 = round(total_votes_20 * dem_pct_20 / 100), \n         repub_votes_20 = round(total_votes_20 * repub_pct_20 / 100)) |&gt; \n  group_by(state_name) |&gt; \n  summarize(dem_total = sum(dem_votes_20),\n            repub_total = sum(repub_votes_20)) |&gt; \n  filter(dem_total &gt; repub_total)\n\n# A tibble: 26 × 3\n   state_name           dem_total repub_total\n   &lt;chr&gt;                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 Arizona                1672127     1661671\n 2 California            11109642     6006031\n 3 Colorado               1804393     1364627\n 4 Connecticut            1080677      715315\n 5 Delaware                296274      200601\n 6 District of Columbia    317324       18595\n 7 Georgia                2473661     2461869\n 8 Hawaii                  366121      196865\n 9 Illinois               3471916     2446931\n10 Maine                   430466      359897\n# ℹ 16 more rows"
  },
  {
    "objectID": "ica/ica-dates.html",
    "href": "ica/ica-dates.html",
    "title": "\n14  Dates\n",
    "section": "",
    "text": "#Exercise Part 1: Same Verbs, New Tricks\nPart A\n\n#Load Data\nlibrary(tidyverse)\npenguins &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')\n\n# Check it out\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\n#Example 1: Single Verb\nggplot(penguins, aes(y = body_mass_g, x = bill_length_mm, color = species)) + \n  geom_point() + \n  facet_wrap(~ sex)\n\n\n\n\n\n# Get data on only Adelie penguins that weigh more than 4700g\npenguins |&gt; \n  filter(species == \"Adelie\", body_mass_g &gt; 4700)\n\n# A tibble: 2 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Biscoe           41              20               203        4725\n2 Adelie  Biscoe           43.2            19               197        4775\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\n# Get data on penguin body mass only\n# Show just the first 6 rows\npenguins |&gt; \n  select(body_mass_g) |&gt; \n  head()\n\n# A tibble: 6 × 1\n  body_mass_g\n        &lt;dbl&gt;\n1        3750\n2        3800\n3        3250\n4          NA\n5        3450\n6        3650\n\n\n\n# Sort the penguins from smallest to largest body mass\n# Show just the first 6 rows\npenguins |&gt; \n  arrange(body_mass_g) |&gt; \n  head()\n\n# A tibble: 6 × 8\n  species   island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;     &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Chinstrap Dream               46.9          16.6               192        2700\n2 Adelie    Biscoe              36.5          16.6               181        2850\n3 Adelie    Biscoe              36.4          17.1               184        2850\n4 Adelie    Biscoe              34.5          18.1               187        2900\n5 Adelie    Dream               33.1          16.1               178        2900\n6 Adelie    Torgersen           38.6          17                 188        2900\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\n# Calculate the average body mass across all penguins\n# Note: na.rm = TRUE removes the NAs from the calculation\npenguins |&gt; \n  summarize(mean = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 1 × 1\n   mean\n  &lt;dbl&gt;\n1 4202.\n\n\n\n# Calculate the average body mass by species\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(mean = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 3 × 2\n  species    mean\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Adelie    3701.\n2 Chinstrap 3733.\n3 Gentoo    5076.\n\n\n\n# Create a new column that records body mass in kilograms, not grams\n# NOTE: there are 1000 g in 1 kg\n# Show just the first 6 rows\npenguins |&gt; \n  mutate(body_mass_kg = body_mass_g/1000) |&gt; \n  head()\n\n# A tibble: 6 × 9\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;, body_mass_kg &lt;dbl&gt;\n\n\n\n#Create Bar Graph\nggplot(penguins, aes(x = species)) + \n  geom_bar()\n\n\n\n\n\n#\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(n())\n\n# A tibble: 3 × 2\n  species   `n()`\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\n\npenguins |&gt; \n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\n\n#Example 2: Multiple Verbs\n\n# Sort Gentoo penguins from biggest to smallest with respect to their \n# Bill length in cm (there are 10 mm in a cm)\npenguins |&gt; \n  filter(species == \"Gentoo\") |&gt; \n  mutate(bill_length_cm = bill_length_mm / 10) |&gt; \n  arrange(desc(bill_length_cm))\n\n# A tibble: 124 × 9\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n 1 Gentoo  Biscoe           59.6          17                 230        6050\n 2 Gentoo  Biscoe           55.9          17                 228        5600\n 3 Gentoo  Biscoe           55.1          16                 230        5850\n 4 Gentoo  Biscoe           54.3          15.7               231        5650\n 5 Gentoo  Biscoe           53.4          15.8               219        5500\n 6 Gentoo  Biscoe           52.5          15.6               221        5450\n 7 Gentoo  Biscoe           52.2          17.1               228        5400\n 8 Gentoo  Biscoe           52.1          17                 230        5550\n 9 Gentoo  Biscoe           51.5          16.3               230        5500\n10 Gentoo  Biscoe           51.3          14.2               218        5300\n# ℹ 114 more rows\n# ℹ 3 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;, bill_length_cm &lt;dbl&gt;\n\n\n\n# Sort the species from smallest to biggest with respect to their \n# average bill length in cm\npenguins |&gt; \n  mutate(bill_length_cm = bill_length_mm / 10) |&gt; \n  group_by(species) |&gt; \n  summarize(mean_bill_length = mean(bill_length_cm, na.rm = TRUE)) |&gt; \n  arrange(desc(mean_bill_length))\n\n# A tibble: 3 × 2\n  species   mean_bill_length\n  &lt;chr&gt;                &lt;dbl&gt;\n1 Chinstrap             4.88\n2 Gentoo                4.75\n3 Adelie                3.88\n\n\n#Example 3: Interpret Code\n#Exercise 1: More Filtering\n\n#Part A\n# Create a dataset with just Adelie and Chinstrap using %in%\n# Pipe this into `count(species)` to confirm that you only have these 2 species\npenguins |&gt;\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) |&gt;\n  count(species)\n\n# A tibble: 2 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n\n\n\n# Create a dataset with just Adelie and Chinstrap using !=\n# Pipe this into `count(species)` to confirm that you only have these 2 species\npenguins |&gt;\n  filter(species != \"Gentoo\") |&gt;\n  count(species)\n\n# A tibble: 2 × 2\n  species       n\n  &lt;chr&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n\n\nPart C: It might get rid of data points even if they have complete information on the variables we need, just because they’re missing info on variables we don’t need.\n#Exercise 2: More Selecting\n\n# First: recall the variable names\nnames(penguins)\n\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\n\n\n# Use a shortcut to keep everything but the year and island variables\npenguins |&gt; \n  select(-year, -island)\n\n# A tibble: 344 × 6\n   species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt; \n 1 Adelie            39.1          18.7               181        3750 male  \n 2 Adelie            39.5          17.4               186        3800 female\n 3 Adelie            40.3          18                 195        3250 female\n 4 Adelie            NA            NA                  NA          NA &lt;NA&gt;  \n 5 Adelie            36.7          19.3               193        3450 female\n 6 Adelie            39.3          20.6               190        3650 male  \n 7 Adelie            38.9          17.8               181        3625 female\n 8 Adelie            39.2          19.6               195        4675 male  \n 9 Adelie            34.1          18.1               193        3475 &lt;NA&gt;  \n10 Adelie            42            20.2               190        4250 &lt;NA&gt;  \n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and the penguin characteristics measured in mm\npenguins |&gt; \n  select(species, ends_with(\"mm\"))\n\n# A tibble: 344 × 4\n   species bill_length_mm bill_depth_mm flipper_length_mm\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n 1 Adelie            39.1          18.7               181\n 2 Adelie            39.5          17.4               186\n 3 Adelie            40.3          18                 195\n 4 Adelie            NA            NA                  NA\n 5 Adelie            36.7          19.3               193\n 6 Adelie            39.3          20.6               190\n 7 Adelie            38.9          17.8               181\n 8 Adelie            39.2          19.6               195\n 9 Adelie            34.1          18.1               193\n10 Adelie            42            20.2               190\n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and bill-related measurements\npenguins |&gt; \n  select(species, starts_with(\"bill\"))\n\n# A tibble: 344 × 3\n   species bill_length_mm bill_depth_mm\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n 1 Adelie            39.1          18.7\n 2 Adelie            39.5          17.4\n 3 Adelie            40.3          18  \n 4 Adelie            NA            NA  \n 5 Adelie            36.7          19.3\n 6 Adelie            39.3          20.6\n 7 Adelie            38.9          17.8\n 8 Adelie            39.2          19.6\n 9 Adelie            34.1          18.1\n10 Adelie            42            20.2\n# ℹ 334 more rows\n\n\n\n# Use a shortcut to keep only species and the length-related characteristics\npenguins |&gt; \n  select(species, contains(\"length\"))\n\n# A tibble: 344 × 3\n   species bill_length_mm flipper_length_mm\n   &lt;chr&gt;            &lt;dbl&gt;             &lt;dbl&gt;\n 1 Adelie            39.1               181\n 2 Adelie            39.5               186\n 3 Adelie            40.3               195\n 4 Adelie            NA                  NA\n 5 Adelie            36.7               193\n 6 Adelie            39.3               190\n 7 Adelie            38.9               181\n 8 Adelie            39.2               195\n 9 Adelie            34.1               193\n10 Adelie            42                 190\n# ℹ 334 more rows\n\n\n#Exercise 3: Arranging, counting, & grouping by multiple variables\n\n# Change this code to sort the penguins by species, and then island name\n# NOTE: The first row should be an Adelie penguin living on Biscoe island\npenguins |&gt; \n  arrange(species, island) |&gt; \n  head()\n\n# A tibble: 6 × 8\n  species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Biscoe           37.8          18.3               174        3400\n2 Adelie  Biscoe           37.7          18.7               180        3600\n3 Adelie  Biscoe           35.9          19.2               189        3800\n4 Adelie  Biscoe           38.2          18.1               185        3950\n5 Adelie  Biscoe           38.8          17.2               180        3800\n6 Adelie  Biscoe           35.3          18.9               187        3800\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\n# Change this code to count the number of male/female penguins observed for each species\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\n\n# Change this code to calculate the average body mass by species and sex\npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(mean = mean(body_mass_g, na.rm = TRUE))\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex     mean\n  &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie    female 3369.\n2 Adelie    male   4043.\n3 Adelie    &lt;NA&gt;   3540 \n4 Chinstrap female 3527.\n5 Chinstrap male   3939.\n6 Gentoo    female 4680.\n7 Gentoo    male   5485.\n8 Gentoo    &lt;NA&gt;   4588.\n\n\n#Exercise 4: Dates\n\n# Get today's date\nas.Date(today())\n\n[1] \"2025-05-06\"\n\n\n\n# Let's store this as \"today\" so we can work with it below\ntoday &lt;- as.Date(today())\n\n# Check out the class of this object\nclass(today)\n\n[1] \"Date\"\n\n\n\n# Records just the 4-digit year\nyear(today)\n\n[1] 2025\n\n\n\n# Today's month, as a number or label\nmonth(today)\n\n[1] 5\n\n\n\nmonth(today, label = TRUE)\n\n[1] May\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n\n\n# This is the week of the year (1-52)\nweek(today)\n\n[1] 18\n\n\n\n# Day of the month (1-31) and day of the year (1-366)\nmday(today)\n\n[1] 6\n\n\n\nyday(today)  # This is often called the \"Julian day\"\n\n[1] 126\n\n\n\n# Day of the week as a number or label\nwday(today)\n\n[1] 3\n\n\n\nwday(today, label = TRUE)\n\n[1] Tue\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\n\n# today is on or after Feb 14, 2024\ntoday &gt;= ymd(\"2024-02-14\")\n\n[1] TRUE\n\n\n\n# today is not before Feb 14, 2024\ntoday &lt; ymd(\"2024-02-14\")\n\n[1] FALSE"
  },
  {
    "objectID": "ica/ica-reshaping.html",
    "href": "ica/ica-reshaping.html",
    "title": "\n15  Reshaping In-Class Activities\n",
    "section": "",
    "text": "library(tidyverse)\npenguins &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')\n\n\n# Using count()\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n# Using group_by() and summarize()\npenguins |&gt; \n  group_by(species, sex) |&gt;\n  summarize (n())\n\n# A tibble: 8 × 3\n# Groups:   species [3]\n  species   sex    `n()`\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n#Relative frequencies \npenguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(n=n()) |&gt;\n  mutate(proportion = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   species [3]\n  species   sex        n proportion\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    female    73     0.480 \n2 Adelie    male      73     0.480 \n3 Adelie    &lt;NA&gt;       6     0.0395\n4 Chinstrap female    34     0.5   \n5 Chinstrap male      34     0.5   \n6 Gentoo    female    58     0.468 \n7 Gentoo    male      61     0.492 \n8 Gentoo    &lt;NA&gt;       5     0.0403\n\n\n\npenguin_avg &lt;- penguins |&gt; \n  group_by(species, sex) |&gt; \n  summarize(avg_body_mass = mean(body_mass_g, na.rm = TRUE)) |&gt; \n  na.omit()\n\n\n# Units of observation = ???\nhead(penguins)\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;chr&gt;, year &lt;dbl&gt;\n\n\n\n# Units of observation = ???\nhead(penguin_avg)\n\n# A tibble: 6 × 3\n# Groups:   species [3]\n  species   sex    avg_body_mass\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 Adelie    female         3369.\n2 Adelie    male           4043.\n3 Chinstrap female         3527.\n4 Chinstrap male           3939.\n5 Gentoo    female         4680.\n6 Gentoo    male           5485."
  },
  {
    "objectID": "ica/ica-factors.html",
    "href": "ica/ica-factors.html",
    "title": "\n16  Factors\n",
    "section": "",
    "text": "#Example 1 \nlibrary(tidyverse)\nelections &lt;- read.csv(\"https://mac-stat.github.io/data/election_2020_county.csv\") |&gt; \n  select(state_abbr, historical, county_name, total_votes_20, repub_pct_20, dem_pct_20) |&gt; \n  mutate(dem_support_20 = case_when(\n    (repub_pct_20 - dem_pct_20 &gt;= 5) ~ \"low\",\n    (repub_pct_20 - dem_pct_20 &lt;= -5) ~ \"high\",\n    .default = \"medium\"))\n\n# Check It Out\nhead(elections)  \n\n  state_abbr historical    county_name total_votes_20 repub_pct_20 dem_pct_20\n1         AL        red Autauga County          27770        71.44      27.02\n2         AL        red Baldwin County         109679        76.17      22.41\n3         AL        red Barbour County          10518        53.45      45.79\n4         AL        red    Bibb County           9595        78.43      20.70\n5         AL        red  Blount County          27588        89.57       9.57\n6         AL        red Bullock County           4613        24.84      74.70\n  dem_support_20\n1            low\n2            low\n3            low\n4            low\n5            low\n6           high\n\n\n\n# Download Grades Data (Get Rid Of Duplicate Rows!)\ngrades &lt;- read.csv(\"https://mac-stat.github.io/data/grades.csv\") |&gt; \n  distinct(sid, sessionID, .keep_all = TRUE)\n\n# Check it out\nhead(grades)\n\n     sid grade   sessionID\n1 S31185    D+ session1784\n2 S31185    B+ session1785\n3 S31185    A- session1791\n4 S31185    B+ session1792\n5 S31185    B- session1794\n6 S31185    C+ session1795\n\n\n\n#Explore Number Of Times Each Grade Was Assigned: \ngrade_distribution &lt;- grades |&gt; \n  count(grade)\n\nhead(grade_distribution)\n\n  grade    n\n1     A 1506\n2    A- 1381\n3    AU   27\n4     B  804\n5    B+ 1003\n6    B-  330\n\n\nExercise 1: Changing Order\n\n#Change Order Of Colums \ngrade_distribution |&gt;\n  mutate(grade = fct_relevel(grade, c(\"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"S\", \"AU\"))) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\n\n\n\n\n\ngrade_distribution |&gt;\n  mutate(grade = fct_reorder(grade, n)) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\n\n\n\n\n\ngrade_distribution |&gt;\n  mutate(grade = fct_reorder(grade, n, .desc = TRUE)) |&gt;\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()\n\n\n\n\n#Exercise 2: Changing Factor Level Labels\n\ngrade_distribution |&gt;\n  mutate(grade = fct_relevel(grade, c(\"A\", \"A-\", \"B+\", \"B\", \"B-\", \"C+\", \"C\", \"C-\", \"D+\", \"D\", \"D-\", \"NC\", \"S\", \"AU\"))) |&gt;\n  mutate(grade = fct_recode(grade, \"Satisfactory\" = \"S\", \"Audit\" = \"AU\")) |&gt;  # Multiple pieces go into the last 2 blanks\n  ggplot(aes(x = grade, y = n)) +\n    geom_col()"
  }
]